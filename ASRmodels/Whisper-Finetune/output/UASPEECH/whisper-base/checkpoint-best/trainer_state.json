{
  "best_metric": 0.35060468316078186,
  "best_model_checkpoint": "output/UASPEECH/whisper-base/checkpoint-5000",
  "epoch": 0.39676241866370415,
  "eval_steps": 1000,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007935248373274084,
      "grad_norm": 0.8238619565963745,
      "learning_rate": 0.0009987551647420278,
      "loss": 2.2416,
      "step": 100
    },
    {
      "epoch": 0.01587049674654817,
      "grad_norm": 0.969124972820282,
      "learning_rate": 0.0009961065790867678,
      "loss": 0.5444,
      "step": 200
    },
    {
      "epoch": 0.02380574511982225,
      "grad_norm": 0.60176020860672,
      "learning_rate": 0.0009934579934315075,
      "loss": 0.4742,
      "step": 300
    },
    {
      "epoch": 0.03174099349309634,
      "grad_norm": 0.9128758311271667,
      "learning_rate": 0.0009908094077762475,
      "loss": 0.4226,
      "step": 400
    },
    {
      "epoch": 0.03967624186637042,
      "grad_norm": 0.6878893971443176,
      "learning_rate": 0.0009881608221209875,
      "loss": 0.3169,
      "step": 500
    },
    {
      "epoch": 0.0476114902396445,
      "grad_norm": 0.8001287579536438,
      "learning_rate": 0.0009855122364657272,
      "loss": 0.2788,
      "step": 600
    },
    {
      "epoch": 0.05554673861291858,
      "grad_norm": 0.7880486845970154,
      "learning_rate": 0.0009828636508104672,
      "loss": 0.2393,
      "step": 700
    },
    {
      "epoch": 0.06348198698619267,
      "grad_norm": 1.1953388452529907,
      "learning_rate": 0.0009802150651552072,
      "loss": 0.2134,
      "step": 800
    },
    {
      "epoch": 0.07141723535946676,
      "grad_norm": 0.22471226751804352,
      "learning_rate": 0.000977566479499947,
      "loss": 0.1933,
      "step": 900
    },
    {
      "epoch": 0.07935248373274084,
      "grad_norm": 0.49256181716918945,
      "learning_rate": 0.000974917893844687,
      "loss": 0.2018,
      "step": 1000
    },
    {
      "epoch": 0.07935248373274084,
      "eval_loss": 0.5227776169776917,
      "eval_runtime": 141.0498,
      "eval_samples_per_second": 128.153,
      "eval_steps_per_second": 16.023,
      "step": 1000
    },
    {
      "epoch": 0.08728773210601491,
      "grad_norm": 0.7801909446716309,
      "learning_rate": 0.0009722693081894268,
      "loss": 0.1857,
      "step": 1100
    },
    {
      "epoch": 0.095222980479289,
      "grad_norm": 0.8029763698577881,
      "learning_rate": 0.0009696207225341668,
      "loss": 0.1496,
      "step": 1200
    },
    {
      "epoch": 0.10315822885256308,
      "grad_norm": 0.9263930320739746,
      "learning_rate": 0.0009669721368789067,
      "loss": 0.1691,
      "step": 1300
    },
    {
      "epoch": 0.11109347722583716,
      "grad_norm": 0.7702046036720276,
      "learning_rate": 0.0009643235512236466,
      "loss": 0.1445,
      "step": 1400
    },
    {
      "epoch": 0.11902872559911125,
      "grad_norm": 0.42328760027885437,
      "learning_rate": 0.0009616749655683866,
      "loss": 0.1223,
      "step": 1500
    },
    {
      "epoch": 0.12696397397238535,
      "grad_norm": 0.6705081462860107,
      "learning_rate": 0.0009590263799131263,
      "loss": 0.1215,
      "step": 1600
    },
    {
      "epoch": 0.13489922234565943,
      "grad_norm": 0.9606318473815918,
      "learning_rate": 0.0009563777942578663,
      "loss": 0.1009,
      "step": 1700
    },
    {
      "epoch": 0.14283447071893351,
      "grad_norm": 1.9252169132232666,
      "learning_rate": 0.0009537292086026063,
      "loss": 0.1197,
      "step": 1800
    },
    {
      "epoch": 0.1507697190922076,
      "grad_norm": 0.28232717514038086,
      "learning_rate": 0.0009510806229473461,
      "loss": 0.1154,
      "step": 1900
    },
    {
      "epoch": 0.15870496746548168,
      "grad_norm": 0.8973149061203003,
      "learning_rate": 0.000948432037292086,
      "loss": 0.1068,
      "step": 2000
    },
    {
      "epoch": 0.15870496746548168,
      "eval_loss": 0.40134257078170776,
      "eval_runtime": 140.4211,
      "eval_samples_per_second": 128.727,
      "eval_steps_per_second": 16.094,
      "step": 2000
    },
    {
      "epoch": 0.16664021583875574,
      "grad_norm": 0.1296689510345459,
      "learning_rate": 0.000945783451636826,
      "loss": 0.0979,
      "step": 2100
    },
    {
      "epoch": 0.17457546421202982,
      "grad_norm": 0.1763535887002945,
      "learning_rate": 0.0009431348659815658,
      "loss": 0.1004,
      "step": 2200
    },
    {
      "epoch": 0.1825107125853039,
      "grad_norm": 0.513003408908844,
      "learning_rate": 0.0009404862803263058,
      "loss": 0.0911,
      "step": 2300
    },
    {
      "epoch": 0.190445960958578,
      "grad_norm": 0.4744727611541748,
      "learning_rate": 0.0009378376946710456,
      "loss": 0.0821,
      "step": 2400
    },
    {
      "epoch": 0.19838120933185208,
      "grad_norm": 0.7731518745422363,
      "learning_rate": 0.0009351891090157856,
      "loss": 0.0785,
      "step": 2500
    },
    {
      "epoch": 0.20631645770512616,
      "grad_norm": 0.6668241620063782,
      "learning_rate": 0.0009325405233605255,
      "loss": 0.0777,
      "step": 2600
    },
    {
      "epoch": 0.21425170607840024,
      "grad_norm": 1.1341969966888428,
      "learning_rate": 0.000929918423561818,
      "loss": 0.0897,
      "step": 2700
    },
    {
      "epoch": 0.22218695445167433,
      "grad_norm": 0.10922116041183472,
      "learning_rate": 0.0009272698379065579,
      "loss": 0.0928,
      "step": 2800
    },
    {
      "epoch": 0.2301222028249484,
      "grad_norm": 0.7277370095252991,
      "learning_rate": 0.0009246212522512978,
      "loss": 0.0688,
      "step": 2900
    },
    {
      "epoch": 0.2380574511982225,
      "grad_norm": 0.10922360420227051,
      "learning_rate": 0.0009219726665960378,
      "loss": 0.0737,
      "step": 3000
    },
    {
      "epoch": 0.2380574511982225,
      "eval_loss": 0.37256506085395813,
      "eval_runtime": 140.7532,
      "eval_samples_per_second": 128.423,
      "eval_steps_per_second": 16.056,
      "step": 3000
    },
    {
      "epoch": 0.24599269957149658,
      "grad_norm": 0.41028261184692383,
      "learning_rate": 0.0009193240809407776,
      "loss": 0.0621,
      "step": 3100
    },
    {
      "epoch": 0.2539279479447707,
      "grad_norm": 1.762805461883545,
      "learning_rate": 0.0009166754952855175,
      "loss": 0.079,
      "step": 3200
    },
    {
      "epoch": 0.2618631963180448,
      "grad_norm": 0.42271673679351807,
      "learning_rate": 0.0009140269096302575,
      "loss": 0.0658,
      "step": 3300
    },
    {
      "epoch": 0.26979844469131886,
      "grad_norm": 1.06522536277771,
      "learning_rate": 0.0009113783239749975,
      "loss": 0.0616,
      "step": 3400
    },
    {
      "epoch": 0.27773369306459295,
      "grad_norm": 0.9231650233268738,
      "learning_rate": 0.0009087297383197373,
      "loss": 0.0718,
      "step": 3500
    },
    {
      "epoch": 0.28566894143786703,
      "grad_norm": 1.0759350061416626,
      "learning_rate": 0.0009060811526644772,
      "loss": 0.0673,
      "step": 3600
    },
    {
      "epoch": 0.2936041898111411,
      "grad_norm": 1.3158036470413208,
      "learning_rate": 0.000903432567009217,
      "loss": 0.0721,
      "step": 3700
    },
    {
      "epoch": 0.3015394381844152,
      "grad_norm": 1.099998116493225,
      "learning_rate": 0.000900783981353957,
      "loss": 0.0698,
      "step": 3800
    },
    {
      "epoch": 0.3094746865576893,
      "grad_norm": 0.19239555299282074,
      "learning_rate": 0.000898135395698697,
      "loss": 0.0697,
      "step": 3900
    },
    {
      "epoch": 0.31740993493096337,
      "grad_norm": 0.302935928106308,
      "learning_rate": 0.0008954868100434368,
      "loss": 0.0585,
      "step": 4000
    },
    {
      "epoch": 0.31740993493096337,
      "eval_loss": 0.36365434527397156,
      "eval_runtime": 141.1343,
      "eval_samples_per_second": 128.077,
      "eval_steps_per_second": 16.013,
      "step": 4000
    },
    {
      "epoch": 0.3253451833042374,
      "grad_norm": 0.5206462740898132,
      "learning_rate": 0.0008928382243881767,
      "loss": 0.0682,
      "step": 4100
    },
    {
      "epoch": 0.3332804316775115,
      "grad_norm": 0.12255159020423889,
      "learning_rate": 0.0008901896387329167,
      "loss": 0.0618,
      "step": 4200
    },
    {
      "epoch": 0.34121568005078556,
      "grad_norm": 1.3511425256729126,
      "learning_rate": 0.0008875410530776566,
      "loss": 0.0556,
      "step": 4300
    },
    {
      "epoch": 0.34915092842405965,
      "grad_norm": 0.8578157424926758,
      "learning_rate": 0.0008848924674223964,
      "loss": 0.0552,
      "step": 4400
    },
    {
      "epoch": 0.35708617679733373,
      "grad_norm": 1.4171770811080933,
      "learning_rate": 0.0008822438817671363,
      "loss": 0.0677,
      "step": 4500
    },
    {
      "epoch": 0.3650214251706078,
      "grad_norm": 0.24177861213684082,
      "learning_rate": 0.0008795952961118763,
      "loss": 0.0462,
      "step": 4600
    },
    {
      "epoch": 0.3729566735438819,
      "grad_norm": 0.0529019720852375,
      "learning_rate": 0.0008769467104566163,
      "loss": 0.0547,
      "step": 4700
    },
    {
      "epoch": 0.380891921917156,
      "grad_norm": 0.20736011862754822,
      "learning_rate": 0.000874298124801356,
      "loss": 0.0551,
      "step": 4800
    },
    {
      "epoch": 0.38882717029043007,
      "grad_norm": 0.36976495385169983,
      "learning_rate": 0.000871649539146096,
      "loss": 0.0499,
      "step": 4900
    },
    {
      "epoch": 0.39676241866370415,
      "grad_norm": 0.03189454227685928,
      "learning_rate": 0.000869000953490836,
      "loss": 0.0486,
      "step": 5000
    },
    {
      "epoch": 0.39676241866370415,
      "eval_loss": 0.35060468316078186,
      "eval_runtime": 140.7395,
      "eval_samples_per_second": 128.436,
      "eval_steps_per_second": 16.058,
      "step": 5000
    }
  ],
  "logging_steps": 100,
  "max_steps": 37806,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6878998528e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

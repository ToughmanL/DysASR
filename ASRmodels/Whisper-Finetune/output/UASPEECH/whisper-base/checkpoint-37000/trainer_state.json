{
  "best_metric": 0.35060468316078186,
  "best_model_checkpoint": "output/UASPEECH/whisper-base/checkpoint-5000",
  "epoch": 2.936041898111411,
  "eval_steps": 1000,
  "global_step": 37000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007935248373274084,
      "grad_norm": 0.8238619565963745,
      "learning_rate": 0.0009987551647420278,
      "loss": 2.2416,
      "step": 100
    },
    {
      "epoch": 0.01587049674654817,
      "grad_norm": 0.969124972820282,
      "learning_rate": 0.0009961065790867678,
      "loss": 0.5444,
      "step": 200
    },
    {
      "epoch": 0.02380574511982225,
      "grad_norm": 0.60176020860672,
      "learning_rate": 0.0009934579934315075,
      "loss": 0.4742,
      "step": 300
    },
    {
      "epoch": 0.03174099349309634,
      "grad_norm": 0.9128758311271667,
      "learning_rate": 0.0009908094077762475,
      "loss": 0.4226,
      "step": 400
    },
    {
      "epoch": 0.03967624186637042,
      "grad_norm": 0.6878893971443176,
      "learning_rate": 0.0009881608221209875,
      "loss": 0.3169,
      "step": 500
    },
    {
      "epoch": 0.0476114902396445,
      "grad_norm": 0.8001287579536438,
      "learning_rate": 0.0009855122364657272,
      "loss": 0.2788,
      "step": 600
    },
    {
      "epoch": 0.05554673861291858,
      "grad_norm": 0.7880486845970154,
      "learning_rate": 0.0009828636508104672,
      "loss": 0.2393,
      "step": 700
    },
    {
      "epoch": 0.06348198698619267,
      "grad_norm": 1.1953388452529907,
      "learning_rate": 0.0009802150651552072,
      "loss": 0.2134,
      "step": 800
    },
    {
      "epoch": 0.07141723535946676,
      "grad_norm": 0.22471226751804352,
      "learning_rate": 0.000977566479499947,
      "loss": 0.1933,
      "step": 900
    },
    {
      "epoch": 0.07935248373274084,
      "grad_norm": 0.49256181716918945,
      "learning_rate": 0.000974917893844687,
      "loss": 0.2018,
      "step": 1000
    },
    {
      "epoch": 0.07935248373274084,
      "eval_loss": 0.5227776169776917,
      "eval_runtime": 141.0498,
      "eval_samples_per_second": 128.153,
      "eval_steps_per_second": 16.023,
      "step": 1000
    },
    {
      "epoch": 0.08728773210601491,
      "grad_norm": 0.7801909446716309,
      "learning_rate": 0.0009722693081894268,
      "loss": 0.1857,
      "step": 1100
    },
    {
      "epoch": 0.095222980479289,
      "grad_norm": 0.8029763698577881,
      "learning_rate": 0.0009696207225341668,
      "loss": 0.1496,
      "step": 1200
    },
    {
      "epoch": 0.10315822885256308,
      "grad_norm": 0.9263930320739746,
      "learning_rate": 0.0009669721368789067,
      "loss": 0.1691,
      "step": 1300
    },
    {
      "epoch": 0.11109347722583716,
      "grad_norm": 0.7702046036720276,
      "learning_rate": 0.0009643235512236466,
      "loss": 0.1445,
      "step": 1400
    },
    {
      "epoch": 0.11902872559911125,
      "grad_norm": 0.42328760027885437,
      "learning_rate": 0.0009616749655683866,
      "loss": 0.1223,
      "step": 1500
    },
    {
      "epoch": 0.12696397397238535,
      "grad_norm": 0.6705081462860107,
      "learning_rate": 0.0009590263799131263,
      "loss": 0.1215,
      "step": 1600
    },
    {
      "epoch": 0.13489922234565943,
      "grad_norm": 0.9606318473815918,
      "learning_rate": 0.0009563777942578663,
      "loss": 0.1009,
      "step": 1700
    },
    {
      "epoch": 0.14283447071893351,
      "grad_norm": 1.9252169132232666,
      "learning_rate": 0.0009537292086026063,
      "loss": 0.1197,
      "step": 1800
    },
    {
      "epoch": 0.1507697190922076,
      "grad_norm": 0.28232717514038086,
      "learning_rate": 0.0009510806229473461,
      "loss": 0.1154,
      "step": 1900
    },
    {
      "epoch": 0.15870496746548168,
      "grad_norm": 0.8973149061203003,
      "learning_rate": 0.000948432037292086,
      "loss": 0.1068,
      "step": 2000
    },
    {
      "epoch": 0.15870496746548168,
      "eval_loss": 0.40134257078170776,
      "eval_runtime": 140.4211,
      "eval_samples_per_second": 128.727,
      "eval_steps_per_second": 16.094,
      "step": 2000
    },
    {
      "epoch": 0.16664021583875574,
      "grad_norm": 0.1296689510345459,
      "learning_rate": 0.000945783451636826,
      "loss": 0.0979,
      "step": 2100
    },
    {
      "epoch": 0.17457546421202982,
      "grad_norm": 0.1763535887002945,
      "learning_rate": 0.0009431348659815658,
      "loss": 0.1004,
      "step": 2200
    },
    {
      "epoch": 0.1825107125853039,
      "grad_norm": 0.513003408908844,
      "learning_rate": 0.0009404862803263058,
      "loss": 0.0911,
      "step": 2300
    },
    {
      "epoch": 0.190445960958578,
      "grad_norm": 0.4744727611541748,
      "learning_rate": 0.0009378376946710456,
      "loss": 0.0821,
      "step": 2400
    },
    {
      "epoch": 0.19838120933185208,
      "grad_norm": 0.7731518745422363,
      "learning_rate": 0.0009351891090157856,
      "loss": 0.0785,
      "step": 2500
    },
    {
      "epoch": 0.20631645770512616,
      "grad_norm": 0.6668241620063782,
      "learning_rate": 0.0009325405233605255,
      "loss": 0.0777,
      "step": 2600
    },
    {
      "epoch": 0.21425170607840024,
      "grad_norm": 1.1341969966888428,
      "learning_rate": 0.000929918423561818,
      "loss": 0.0897,
      "step": 2700
    },
    {
      "epoch": 0.22218695445167433,
      "grad_norm": 0.10922116041183472,
      "learning_rate": 0.0009272698379065579,
      "loss": 0.0928,
      "step": 2800
    },
    {
      "epoch": 0.2301222028249484,
      "grad_norm": 0.7277370095252991,
      "learning_rate": 0.0009246212522512978,
      "loss": 0.0688,
      "step": 2900
    },
    {
      "epoch": 0.2380574511982225,
      "grad_norm": 0.10922360420227051,
      "learning_rate": 0.0009219726665960378,
      "loss": 0.0737,
      "step": 3000
    },
    {
      "epoch": 0.2380574511982225,
      "eval_loss": 0.37256506085395813,
      "eval_runtime": 140.7532,
      "eval_samples_per_second": 128.423,
      "eval_steps_per_second": 16.056,
      "step": 3000
    },
    {
      "epoch": 0.24599269957149658,
      "grad_norm": 0.41028261184692383,
      "learning_rate": 0.0009193240809407776,
      "loss": 0.0621,
      "step": 3100
    },
    {
      "epoch": 0.2539279479447707,
      "grad_norm": 1.762805461883545,
      "learning_rate": 0.0009166754952855175,
      "loss": 0.079,
      "step": 3200
    },
    {
      "epoch": 0.2618631963180448,
      "grad_norm": 0.42271673679351807,
      "learning_rate": 0.0009140269096302575,
      "loss": 0.0658,
      "step": 3300
    },
    {
      "epoch": 0.26979844469131886,
      "grad_norm": 1.06522536277771,
      "learning_rate": 0.0009113783239749975,
      "loss": 0.0616,
      "step": 3400
    },
    {
      "epoch": 0.27773369306459295,
      "grad_norm": 0.9231650233268738,
      "learning_rate": 0.0009087297383197373,
      "loss": 0.0718,
      "step": 3500
    },
    {
      "epoch": 0.28566894143786703,
      "grad_norm": 1.0759350061416626,
      "learning_rate": 0.0009060811526644772,
      "loss": 0.0673,
      "step": 3600
    },
    {
      "epoch": 0.2936041898111411,
      "grad_norm": 1.3158036470413208,
      "learning_rate": 0.000903432567009217,
      "loss": 0.0721,
      "step": 3700
    },
    {
      "epoch": 0.3015394381844152,
      "grad_norm": 1.099998116493225,
      "learning_rate": 0.000900783981353957,
      "loss": 0.0698,
      "step": 3800
    },
    {
      "epoch": 0.3094746865576893,
      "grad_norm": 0.19239555299282074,
      "learning_rate": 0.000898135395698697,
      "loss": 0.0697,
      "step": 3900
    },
    {
      "epoch": 0.31740993493096337,
      "grad_norm": 0.302935928106308,
      "learning_rate": 0.0008954868100434368,
      "loss": 0.0585,
      "step": 4000
    },
    {
      "epoch": 0.31740993493096337,
      "eval_loss": 0.36365434527397156,
      "eval_runtime": 141.1343,
      "eval_samples_per_second": 128.077,
      "eval_steps_per_second": 16.013,
      "step": 4000
    },
    {
      "epoch": 0.3253451833042374,
      "grad_norm": 0.5206462740898132,
      "learning_rate": 0.0008928382243881767,
      "loss": 0.0682,
      "step": 4100
    },
    {
      "epoch": 0.3332804316775115,
      "grad_norm": 0.12255159020423889,
      "learning_rate": 0.0008901896387329167,
      "loss": 0.0618,
      "step": 4200
    },
    {
      "epoch": 0.34121568005078556,
      "grad_norm": 1.3511425256729126,
      "learning_rate": 0.0008875410530776566,
      "loss": 0.0556,
      "step": 4300
    },
    {
      "epoch": 0.34915092842405965,
      "grad_norm": 0.8578157424926758,
      "learning_rate": 0.0008848924674223964,
      "loss": 0.0552,
      "step": 4400
    },
    {
      "epoch": 0.35708617679733373,
      "grad_norm": 1.4171770811080933,
      "learning_rate": 0.0008822438817671363,
      "loss": 0.0677,
      "step": 4500
    },
    {
      "epoch": 0.3650214251706078,
      "grad_norm": 0.24177861213684082,
      "learning_rate": 0.0008795952961118763,
      "loss": 0.0462,
      "step": 4600
    },
    {
      "epoch": 0.3729566735438819,
      "grad_norm": 0.0529019720852375,
      "learning_rate": 0.0008769467104566163,
      "loss": 0.0547,
      "step": 4700
    },
    {
      "epoch": 0.380891921917156,
      "grad_norm": 0.20736011862754822,
      "learning_rate": 0.000874298124801356,
      "loss": 0.0551,
      "step": 4800
    },
    {
      "epoch": 0.38882717029043007,
      "grad_norm": 0.36976495385169983,
      "learning_rate": 0.000871649539146096,
      "loss": 0.0499,
      "step": 4900
    },
    {
      "epoch": 0.39676241866370415,
      "grad_norm": 0.03189454227685928,
      "learning_rate": 0.000869000953490836,
      "loss": 0.0486,
      "step": 5000
    },
    {
      "epoch": 0.39676241866370415,
      "eval_loss": 0.35060468316078186,
      "eval_runtime": 140.7395,
      "eval_samples_per_second": 128.436,
      "eval_steps_per_second": 16.058,
      "step": 5000
    },
    {
      "epoch": 0.40469766703697824,
      "grad_norm": 0.10164196044206619,
      "learning_rate": 0.0008663523678355758,
      "loss": 0.0455,
      "step": 5100
    },
    {
      "epoch": 0.4126329154102523,
      "grad_norm": 0.14597296714782715,
      "learning_rate": 0.0008637037821803158,
      "loss": 0.0466,
      "step": 5200
    },
    {
      "epoch": 0.4205681637835264,
      "grad_norm": 0.4482822120189667,
      "learning_rate": 0.0008610551965250556,
      "loss": 0.0504,
      "step": 5300
    },
    {
      "epoch": 0.4285034121568005,
      "grad_norm": 1.0635582208633423,
      "learning_rate": 0.0008584066108697955,
      "loss": 0.0518,
      "step": 5400
    },
    {
      "epoch": 0.4364386605300746,
      "grad_norm": 1.4843603372573853,
      "learning_rate": 0.0008557580252145355,
      "loss": 0.0499,
      "step": 5500
    },
    {
      "epoch": 0.44437390890334866,
      "grad_norm": 2.4062821865081787,
      "learning_rate": 0.0008531094395592754,
      "loss": 0.0479,
      "step": 5600
    },
    {
      "epoch": 0.45230915727662274,
      "grad_norm": 0.2777707278728485,
      "learning_rate": 0.0008504608539040152,
      "loss": 0.0337,
      "step": 5700
    },
    {
      "epoch": 0.4602444056498968,
      "grad_norm": 0.11338052898645401,
      "learning_rate": 0.0008478122682487552,
      "loss": 0.0371,
      "step": 5800
    },
    {
      "epoch": 0.4681796540231709,
      "grad_norm": 0.9983019232749939,
      "learning_rate": 0.0008451636825934951,
      "loss": 0.0422,
      "step": 5900
    },
    {
      "epoch": 0.476114902396445,
      "grad_norm": 0.9861355423927307,
      "learning_rate": 0.0008425150969382351,
      "loss": 0.0372,
      "step": 6000
    },
    {
      "epoch": 0.476114902396445,
      "eval_loss": 0.3534702658653259,
      "eval_runtime": 142.1443,
      "eval_samples_per_second": 127.167,
      "eval_steps_per_second": 15.899,
      "step": 6000
    },
    {
      "epoch": 0.4840501507697191,
      "grad_norm": 0.764204740524292,
      "learning_rate": 0.0008398665112829748,
      "loss": 0.0393,
      "step": 6100
    },
    {
      "epoch": 0.49198539914299316,
      "grad_norm": 0.15790925920009613,
      "learning_rate": 0.0008372179256277148,
      "loss": 0.0452,
      "step": 6200
    },
    {
      "epoch": 0.49992064751626725,
      "grad_norm": 0.5340696573257446,
      "learning_rate": 0.0008345693399724548,
      "loss": 0.0491,
      "step": 6300
    },
    {
      "epoch": 0.5078558958895414,
      "grad_norm": 0.294526070356369,
      "learning_rate": 0.0008319207543171946,
      "loss": 0.0364,
      "step": 6400
    },
    {
      "epoch": 0.5157911442628155,
      "grad_norm": 1.161915898323059,
      "learning_rate": 0.0008292721686619346,
      "loss": 0.0376,
      "step": 6500
    },
    {
      "epoch": 0.5237263926360896,
      "grad_norm": 0.2446097880601883,
      "learning_rate": 0.0008266235830066745,
      "loss": 0.0462,
      "step": 6600
    },
    {
      "epoch": 0.5316616410093636,
      "grad_norm": 0.2954464852809906,
      "learning_rate": 0.000824001483207967,
      "loss": 0.0447,
      "step": 6700
    },
    {
      "epoch": 0.5395968893826377,
      "grad_norm": 1.0643821954727173,
      "learning_rate": 0.0008213528975527069,
      "loss": 0.0365,
      "step": 6800
    },
    {
      "epoch": 0.5475321377559118,
      "grad_norm": 0.4855395257472992,
      "learning_rate": 0.0008187043118974467,
      "loss": 0.0327,
      "step": 6900
    },
    {
      "epoch": 0.5554673861291859,
      "grad_norm": 0.9301061034202576,
      "learning_rate": 0.0008160557262421867,
      "loss": 0.0372,
      "step": 7000
    },
    {
      "epoch": 0.5554673861291859,
      "eval_loss": 0.3739473223686218,
      "eval_runtime": 140.7213,
      "eval_samples_per_second": 128.452,
      "eval_steps_per_second": 16.06,
      "step": 7000
    },
    {
      "epoch": 0.56340263450246,
      "grad_norm": 0.15118321776390076,
      "learning_rate": 0.0008134071405869266,
      "loss": 0.0355,
      "step": 7100
    },
    {
      "epoch": 0.5713378828757341,
      "grad_norm": 1.2726582288742065,
      "learning_rate": 0.0008107585549316666,
      "loss": 0.0347,
      "step": 7200
    },
    {
      "epoch": 0.5792731312490081,
      "grad_norm": 1.083234429359436,
      "learning_rate": 0.0008081099692764064,
      "loss": 0.0391,
      "step": 7300
    },
    {
      "epoch": 0.5872083796222822,
      "grad_norm": 0.8552020192146301,
      "learning_rate": 0.0008054613836211463,
      "loss": 0.0326,
      "step": 7400
    },
    {
      "epoch": 0.5951436279955563,
      "grad_norm": 0.5056121349334717,
      "learning_rate": 0.0008028127979658863,
      "loss": 0.0281,
      "step": 7500
    },
    {
      "epoch": 0.6030788763688304,
      "grad_norm": 0.20677538216114044,
      "learning_rate": 0.0008001642123106262,
      "loss": 0.0385,
      "step": 7600
    },
    {
      "epoch": 0.6110141247421045,
      "grad_norm": 1.0265320539474487,
      "learning_rate": 0.000797515626655366,
      "loss": 0.0425,
      "step": 7700
    },
    {
      "epoch": 0.6189493731153786,
      "grad_norm": 0.11280139535665512,
      "learning_rate": 0.000794867041000106,
      "loss": 0.0265,
      "step": 7800
    },
    {
      "epoch": 0.6268846214886526,
      "grad_norm": 0.6484808921813965,
      "learning_rate": 0.0007922184553448458,
      "loss": 0.0343,
      "step": 7900
    },
    {
      "epoch": 0.6348198698619267,
      "grad_norm": 0.1851295381784439,
      "learning_rate": 0.0007895698696895858,
      "loss": 0.0402,
      "step": 8000
    },
    {
      "epoch": 0.6348198698619267,
      "eval_loss": 0.3730425238609314,
      "eval_runtime": 141.5324,
      "eval_samples_per_second": 127.716,
      "eval_steps_per_second": 15.968,
      "step": 8000
    },
    {
      "epoch": 0.6427551182352007,
      "grad_norm": 0.5255868434906006,
      "learning_rate": 0.0007869212840343257,
      "loss": 0.0297,
      "step": 8100
    },
    {
      "epoch": 0.6506903666084748,
      "grad_norm": 1.1318415403366089,
      "learning_rate": 0.0007842726983790655,
      "loss": 0.0367,
      "step": 8200
    },
    {
      "epoch": 0.6586256149817489,
      "grad_norm": 1.4622318744659424,
      "learning_rate": 0.0007816241127238055,
      "loss": 0.0312,
      "step": 8300
    },
    {
      "epoch": 0.666560863355023,
      "grad_norm": 0.3999136984348297,
      "learning_rate": 0.0007789755270685455,
      "loss": 0.0331,
      "step": 8400
    },
    {
      "epoch": 0.674496111728297,
      "grad_norm": 1.3453201055526733,
      "learning_rate": 0.0007763269414132853,
      "loss": 0.0282,
      "step": 8500
    },
    {
      "epoch": 0.6824313601015711,
      "grad_norm": 0.7908991575241089,
      "learning_rate": 0.0007736783557580252,
      "loss": 0.0332,
      "step": 8600
    },
    {
      "epoch": 0.6903666084748452,
      "grad_norm": 0.7334574460983276,
      "learning_rate": 0.0007710562559593178,
      "loss": 0.0404,
      "step": 8700
    },
    {
      "epoch": 0.6983018568481193,
      "grad_norm": 0.059270039200782776,
      "learning_rate": 0.0007684076703040576,
      "loss": 0.0262,
      "step": 8800
    },
    {
      "epoch": 0.7062371052213934,
      "grad_norm": 0.025917502120137215,
      "learning_rate": 0.0007657590846487975,
      "loss": 0.0328,
      "step": 8900
    },
    {
      "epoch": 0.7141723535946675,
      "grad_norm": 0.1653519719839096,
      "learning_rate": 0.0007631104989935375,
      "loss": 0.0309,
      "step": 9000
    },
    {
      "epoch": 0.7141723535946675,
      "eval_loss": 0.3563418686389923,
      "eval_runtime": 140.8576,
      "eval_samples_per_second": 128.328,
      "eval_steps_per_second": 16.045,
      "step": 9000
    },
    {
      "epoch": 0.7221076019679415,
      "grad_norm": 0.29995274543762207,
      "learning_rate": 0.0007604619133382774,
      "loss": 0.0305,
      "step": 9100
    },
    {
      "epoch": 0.7300428503412156,
      "grad_norm": 0.07123900949954987,
      "learning_rate": 0.0007578133276830172,
      "loss": 0.0253,
      "step": 9200
    },
    {
      "epoch": 0.7379780987144897,
      "grad_norm": 0.18951734900474548,
      "learning_rate": 0.0007551647420277572,
      "loss": 0.0291,
      "step": 9300
    },
    {
      "epoch": 0.7459133470877638,
      "grad_norm": 0.3881966769695282,
      "learning_rate": 0.0007525161563724971,
      "loss": 0.0254,
      "step": 9400
    },
    {
      "epoch": 0.7538485954610379,
      "grad_norm": 0.2065221667289734,
      "learning_rate": 0.000749867570717237,
      "loss": 0.0227,
      "step": 9500
    },
    {
      "epoch": 0.761783843834312,
      "grad_norm": 2.462196111679077,
      "learning_rate": 0.000747218985061977,
      "loss": 0.0373,
      "step": 9600
    },
    {
      "epoch": 0.769719092207586,
      "grad_norm": 0.8588781356811523,
      "learning_rate": 0.0007445703994067167,
      "loss": 0.0298,
      "step": 9700
    },
    {
      "epoch": 0.7776543405808601,
      "grad_norm": 0.1284390240907669,
      "learning_rate": 0.0007419218137514567,
      "loss": 0.031,
      "step": 9800
    },
    {
      "epoch": 0.7855895889541342,
      "grad_norm": 0.08990394324064255,
      "learning_rate": 0.0007392732280961967,
      "loss": 0.0219,
      "step": 9900
    },
    {
      "epoch": 0.7935248373274083,
      "grad_norm": 0.0868615061044693,
      "learning_rate": 0.0007366246424409366,
      "loss": 0.0233,
      "step": 10000
    },
    {
      "epoch": 0.7935248373274083,
      "eval_loss": 0.36077073216438293,
      "eval_runtime": 146.2736,
      "eval_samples_per_second": 123.577,
      "eval_steps_per_second": 15.45,
      "step": 10000
    },
    {
      "epoch": 0.8014600857006824,
      "grad_norm": 0.0711626335978508,
      "learning_rate": 0.0007339760567856764,
      "loss": 0.0345,
      "step": 10100
    },
    {
      "epoch": 0.8093953340739565,
      "grad_norm": 0.9747578501701355,
      "learning_rate": 0.0007313274711304164,
      "loss": 0.0278,
      "step": 10200
    },
    {
      "epoch": 0.8173305824472306,
      "grad_norm": 0.9350556135177612,
      "learning_rate": 0.0007286788854751563,
      "loss": 0.0274,
      "step": 10300
    },
    {
      "epoch": 0.8252658308205046,
      "grad_norm": 0.033096205443143845,
      "learning_rate": 0.0007260302998198962,
      "loss": 0.0164,
      "step": 10400
    },
    {
      "epoch": 0.8332010791937787,
      "grad_norm": 0.47931820154190063,
      "learning_rate": 0.000723381714164636,
      "loss": 0.0206,
      "step": 10500
    },
    {
      "epoch": 0.8411363275670528,
      "grad_norm": 0.019448209553956985,
      "learning_rate": 0.000720733128509376,
      "loss": 0.0289,
      "step": 10600
    },
    {
      "epoch": 0.8490715759403269,
      "grad_norm": 0.1150096133351326,
      "learning_rate": 0.000718084542854116,
      "loss": 0.0223,
      "step": 10700
    },
    {
      "epoch": 0.857006824313601,
      "grad_norm": 1.953445553779602,
      "learning_rate": 0.0007154359571988558,
      "loss": 0.0275,
      "step": 10800
    },
    {
      "epoch": 0.8649420726868751,
      "grad_norm": 0.26209786534309387,
      "learning_rate": 0.0007128138574001484,
      "loss": 0.0233,
      "step": 10900
    },
    {
      "epoch": 0.8728773210601491,
      "grad_norm": 1.0250332355499268,
      "learning_rate": 0.0007101652717448882,
      "loss": 0.0197,
      "step": 11000
    },
    {
      "epoch": 0.8728773210601491,
      "eval_loss": 0.3554880917072296,
      "eval_runtime": 140.2263,
      "eval_samples_per_second": 128.906,
      "eval_steps_per_second": 16.117,
      "step": 11000
    },
    {
      "epoch": 0.8808125694334232,
      "grad_norm": 0.027553943917155266,
      "learning_rate": 0.0007075166860896282,
      "loss": 0.0218,
      "step": 11100
    },
    {
      "epoch": 0.8887478178066973,
      "grad_norm": 1.1270116567611694,
      "learning_rate": 0.0007048681004343681,
      "loss": 0.0252,
      "step": 11200
    },
    {
      "epoch": 0.8966830661799714,
      "grad_norm": 0.15811941027641296,
      "learning_rate": 0.0007022195147791079,
      "loss": 0.0171,
      "step": 11300
    },
    {
      "epoch": 0.9046183145532455,
      "grad_norm": 0.0615217350423336,
      "learning_rate": 0.0006995709291238479,
      "loss": 0.0239,
      "step": 11400
    },
    {
      "epoch": 0.9125535629265196,
      "grad_norm": 0.028621893376111984,
      "learning_rate": 0.0006969223434685878,
      "loss": 0.0237,
      "step": 11500
    },
    {
      "epoch": 0.9204888112997937,
      "grad_norm": 0.4521230161190033,
      "learning_rate": 0.0006942737578133277,
      "loss": 0.022,
      "step": 11600
    },
    {
      "epoch": 0.9284240596730677,
      "grad_norm": 0.10655415803194046,
      "learning_rate": 0.0006916251721580676,
      "loss": 0.0279,
      "step": 11700
    },
    {
      "epoch": 0.9363593080463418,
      "grad_norm": 0.9756056666374207,
      "learning_rate": 0.0006889765865028075,
      "loss": 0.0197,
      "step": 11800
    },
    {
      "epoch": 0.9442945564196159,
      "grad_norm": 0.1785406768321991,
      "learning_rate": 0.0006863280008475474,
      "loss": 0.0209,
      "step": 11900
    },
    {
      "epoch": 0.95222980479289,
      "grad_norm": 0.2654322683811188,
      "learning_rate": 0.0006836794151922874,
      "loss": 0.0234,
      "step": 12000
    },
    {
      "epoch": 0.95222980479289,
      "eval_loss": 0.3751952052116394,
      "eval_runtime": 148.0462,
      "eval_samples_per_second": 122.097,
      "eval_steps_per_second": 15.266,
      "step": 12000
    },
    {
      "epoch": 0.9601650531661641,
      "grad_norm": 0.23093828558921814,
      "learning_rate": 0.0006810308295370272,
      "loss": 0.0201,
      "step": 12100
    },
    {
      "epoch": 0.9681003015394382,
      "grad_norm": 1.143006682395935,
      "learning_rate": 0.0006783822438817672,
      "loss": 0.0208,
      "step": 12200
    },
    {
      "epoch": 0.9760355499127122,
      "grad_norm": 0.1554020345211029,
      "learning_rate": 0.000675733658226507,
      "loss": 0.018,
      "step": 12300
    },
    {
      "epoch": 0.9839707982859863,
      "grad_norm": 0.04779691994190216,
      "learning_rate": 0.000673085072571247,
      "loss": 0.0154,
      "step": 12400
    },
    {
      "epoch": 0.9919060466592604,
      "grad_norm": 0.07551568746566772,
      "learning_rate": 0.0006704364869159869,
      "loss": 0.0205,
      "step": 12500
    },
    {
      "epoch": 0.9998412950325345,
      "grad_norm": 0.7792482376098633,
      "learning_rate": 0.0006677879012607267,
      "loss": 0.0187,
      "step": 12600
    },
    {
      "epoch": 1.0077765434058086,
      "grad_norm": 0.7432326674461365,
      "learning_rate": 0.0006651393156054667,
      "loss": 0.0103,
      "step": 12700
    },
    {
      "epoch": 1.0157117917790828,
      "grad_norm": 0.95389723777771,
      "learning_rate": 0.0006624907299502067,
      "loss": 0.0183,
      "step": 12800
    },
    {
      "epoch": 1.0236470401523567,
      "grad_norm": 0.019950225949287415,
      "learning_rate": 0.0006598421442949464,
      "loss": 0.017,
      "step": 12900
    },
    {
      "epoch": 1.031582288525631,
      "grad_norm": 0.2898557782173157,
      "learning_rate": 0.0006571935586396864,
      "loss": 0.0114,
      "step": 13000
    },
    {
      "epoch": 1.031582288525631,
      "eval_loss": 0.3907414674758911,
      "eval_runtime": 144.7821,
      "eval_samples_per_second": 124.85,
      "eval_steps_per_second": 15.61,
      "step": 13000
    },
    {
      "epoch": 1.039517536898905,
      "grad_norm": 0.22070804238319397,
      "learning_rate": 0.0006545714588409789,
      "loss": 0.0152,
      "step": 13100
    },
    {
      "epoch": 1.047452785272179,
      "grad_norm": 0.10037629306316376,
      "learning_rate": 0.0006519228731857188,
      "loss": 0.011,
      "step": 13200
    },
    {
      "epoch": 1.055388033645453,
      "grad_norm": 0.2819328308105469,
      "learning_rate": 0.0006492742875304587,
      "loss": 0.0085,
      "step": 13300
    },
    {
      "epoch": 1.0633232820187273,
      "grad_norm": 0.8894152045249939,
      "learning_rate": 0.0006466257018751987,
      "loss": 0.0144,
      "step": 13400
    },
    {
      "epoch": 1.0712585303920013,
      "grad_norm": 0.11554261296987534,
      "learning_rate": 0.0006439771162199386,
      "loss": 0.0135,
      "step": 13500
    },
    {
      "epoch": 1.0791937787652754,
      "grad_norm": 0.028417445719242096,
      "learning_rate": 0.0006413285305646784,
      "loss": 0.0156,
      "step": 13600
    },
    {
      "epoch": 1.0871290271385494,
      "grad_norm": 1.026055097579956,
      "learning_rate": 0.0006386799449094184,
      "loss": 0.0143,
      "step": 13700
    },
    {
      "epoch": 1.0950642755118236,
      "grad_norm": 0.13452760875225067,
      "learning_rate": 0.0006360313592541583,
      "loss": 0.0164,
      "step": 13800
    },
    {
      "epoch": 1.1029995238850976,
      "grad_norm": 0.06219010800123215,
      "learning_rate": 0.0006333827735988982,
      "loss": 0.01,
      "step": 13900
    },
    {
      "epoch": 1.1109347722583718,
      "grad_norm": 0.9011316895484924,
      "learning_rate": 0.0006307341879436382,
      "loss": 0.0132,
      "step": 14000
    },
    {
      "epoch": 1.1109347722583718,
      "eval_loss": 0.3806982934474945,
      "eval_runtime": 145.2729,
      "eval_samples_per_second": 124.428,
      "eval_steps_per_second": 15.557,
      "step": 14000
    },
    {
      "epoch": 1.1188700206316458,
      "grad_norm": 0.011523807421326637,
      "learning_rate": 0.0006280856022883779,
      "loss": 0.0144,
      "step": 14100
    },
    {
      "epoch": 1.1268052690049197,
      "grad_norm": 0.04711667820811272,
      "learning_rate": 0.0006254370166331179,
      "loss": 0.014,
      "step": 14200
    },
    {
      "epoch": 1.134740517378194,
      "grad_norm": 0.05589485540986061,
      "learning_rate": 0.0006227884309778579,
      "loss": 0.0108,
      "step": 14300
    },
    {
      "epoch": 1.1426757657514681,
      "grad_norm": 1.1293290853500366,
      "learning_rate": 0.0006201398453225977,
      "loss": 0.0171,
      "step": 14400
    },
    {
      "epoch": 1.150611014124742,
      "grad_norm": 0.06057727336883545,
      "learning_rate": 0.0006174912596673376,
      "loss": 0.0108,
      "step": 14500
    },
    {
      "epoch": 1.158546262498016,
      "grad_norm": 0.6770337820053101,
      "learning_rate": 0.0006148426740120776,
      "loss": 0.015,
      "step": 14600
    },
    {
      "epoch": 1.1664815108712903,
      "grad_norm": 0.32051798701286316,
      "learning_rate": 0.0006121940883568175,
      "loss": 0.0129,
      "step": 14700
    },
    {
      "epoch": 1.1744167592445645,
      "grad_norm": 0.6682961583137512,
      "learning_rate": 0.0006095455027015574,
      "loss": 0.0093,
      "step": 14800
    },
    {
      "epoch": 1.1823520076178384,
      "grad_norm": 0.02649584226310253,
      "learning_rate": 0.0006068969170462972,
      "loss": 0.0081,
      "step": 14900
    },
    {
      "epoch": 1.1902872559911124,
      "grad_norm": 1.1184298992156982,
      "learning_rate": 0.0006042483313910372,
      "loss": 0.0115,
      "step": 15000
    },
    {
      "epoch": 1.1902872559911124,
      "eval_loss": 0.3853401839733124,
      "eval_runtime": 144.1852,
      "eval_samples_per_second": 125.367,
      "eval_steps_per_second": 15.674,
      "step": 15000
    },
    {
      "epoch": 1.1982225043643866,
      "grad_norm": 1.098984718322754,
      "learning_rate": 0.0006015997457357771,
      "loss": 0.0153,
      "step": 15100
    },
    {
      "epoch": 1.2061577527376608,
      "grad_norm": 0.6832365393638611,
      "learning_rate": 0.0005989776459370696,
      "loss": 0.0136,
      "step": 15200
    },
    {
      "epoch": 1.2140930011109348,
      "grad_norm": 1.7587929964065552,
      "learning_rate": 0.0005963290602818095,
      "loss": 0.0125,
      "step": 15300
    },
    {
      "epoch": 1.2220282494842087,
      "grad_norm": 0.06652340292930603,
      "learning_rate": 0.0005936804746265494,
      "loss": 0.0117,
      "step": 15400
    },
    {
      "epoch": 1.229963497857483,
      "grad_norm": 0.011846515350043774,
      "learning_rate": 0.0005910318889712894,
      "loss": 0.0154,
      "step": 15500
    },
    {
      "epoch": 1.2378987462307571,
      "grad_norm": 0.0037419081199914217,
      "learning_rate": 0.0005883833033160292,
      "loss": 0.0111,
      "step": 15600
    },
    {
      "epoch": 1.245833994604031,
      "grad_norm": 0.07800035178661346,
      "learning_rate": 0.0005857347176607691,
      "loss": 0.009,
      "step": 15700
    },
    {
      "epoch": 1.253769242977305,
      "grad_norm": 0.07969563454389572,
      "learning_rate": 0.0005830861320055091,
      "loss": 0.011,
      "step": 15800
    },
    {
      "epoch": 1.2617044913505793,
      "grad_norm": 0.16582925617694855,
      "learning_rate": 0.000580437546350249,
      "loss": 0.0125,
      "step": 15900
    },
    {
      "epoch": 1.2696397397238535,
      "grad_norm": 0.019666826352477074,
      "learning_rate": 0.0005777889606949889,
      "loss": 0.0105,
      "step": 16000
    },
    {
      "epoch": 1.2696397397238535,
      "eval_loss": 0.38402536511421204,
      "eval_runtime": 146.3605,
      "eval_samples_per_second": 123.503,
      "eval_steps_per_second": 15.441,
      "step": 16000
    },
    {
      "epoch": 1.2775749880971274,
      "grad_norm": 0.7342113852500916,
      "learning_rate": 0.0005751403750397288,
      "loss": 0.0116,
      "step": 16100
    },
    {
      "epoch": 1.2855102364704014,
      "grad_norm": 0.2821444869041443,
      "learning_rate": 0.0005724917893844687,
      "loss": 0.0127,
      "step": 16200
    },
    {
      "epoch": 1.2934454848436756,
      "grad_norm": 0.914451003074646,
      "learning_rate": 0.0005698432037292086,
      "loss": 0.0129,
      "step": 16300
    },
    {
      "epoch": 1.3013807332169498,
      "grad_norm": 0.00954948179423809,
      "learning_rate": 0.0005671946180739486,
      "loss": 0.0104,
      "step": 16400
    },
    {
      "epoch": 1.3093159815902238,
      "grad_norm": 0.02039501816034317,
      "learning_rate": 0.0005645460324186884,
      "loss": 0.0128,
      "step": 16500
    },
    {
      "epoch": 1.3172512299634977,
      "grad_norm": 0.004559156019240618,
      "learning_rate": 0.0005618974467634283,
      "loss": 0.0079,
      "step": 16600
    },
    {
      "epoch": 1.325186478336772,
      "grad_norm": 0.233256533741951,
      "learning_rate": 0.0005592488611081683,
      "loss": 0.0161,
      "step": 16700
    },
    {
      "epoch": 1.3331217267100461,
      "grad_norm": 0.05947257578372955,
      "learning_rate": 0.0005566002754529082,
      "loss": 0.0144,
      "step": 16800
    },
    {
      "epoch": 1.3410569750833201,
      "grad_norm": 0.048405785113573074,
      "learning_rate": 0.000553951689797648,
      "loss": 0.0125,
      "step": 16900
    },
    {
      "epoch": 1.348992223456594,
      "grad_norm": 0.3556612432003021,
      "learning_rate": 0.0005513031041423879,
      "loss": 0.009,
      "step": 17000
    },
    {
      "epoch": 1.348992223456594,
      "eval_loss": 0.41068539023399353,
      "eval_runtime": 142.7531,
      "eval_samples_per_second": 126.624,
      "eval_steps_per_second": 15.832,
      "step": 17000
    },
    {
      "epoch": 1.3569274718298683,
      "grad_norm": 0.34682077169418335,
      "learning_rate": 0.0005486545184871279,
      "loss": 0.0119,
      "step": 17100
    },
    {
      "epoch": 1.3648627202031425,
      "grad_norm": 0.020001046359539032,
      "learning_rate": 0.0005460059328318679,
      "loss": 0.008,
      "step": 17200
    },
    {
      "epoch": 1.3727979685764164,
      "grad_norm": 0.014780604280531406,
      "learning_rate": 0.0005433573471766076,
      "loss": 0.0089,
      "step": 17300
    },
    {
      "epoch": 1.3807332169496904,
      "grad_norm": 0.04566260054707527,
      "learning_rate": 0.0005407352473779003,
      "loss": 0.0092,
      "step": 17400
    },
    {
      "epoch": 1.3886684653229646,
      "grad_norm": 0.07523025572299957,
      "learning_rate": 0.0005380866617226401,
      "loss": 0.0113,
      "step": 17500
    },
    {
      "epoch": 1.3966037136962388,
      "grad_norm": 0.028726236894726753,
      "learning_rate": 0.00053543807606738,
      "loss": 0.015,
      "step": 17600
    },
    {
      "epoch": 1.4045389620695128,
      "grad_norm": 0.06492943316698074,
      "learning_rate": 0.00053278949041212,
      "loss": 0.0101,
      "step": 17700
    },
    {
      "epoch": 1.4124742104427868,
      "grad_norm": 0.06148208677768707,
      "learning_rate": 0.0005301409047568598,
      "loss": 0.0113,
      "step": 17800
    },
    {
      "epoch": 1.420409458816061,
      "grad_norm": 0.03393057361245155,
      "learning_rate": 0.0005274923191015998,
      "loss": 0.0166,
      "step": 17900
    },
    {
      "epoch": 1.4283447071893351,
      "grad_norm": 0.03579244762659073,
      "learning_rate": 0.0005248437334463397,
      "loss": 0.0121,
      "step": 18000
    },
    {
      "epoch": 1.4283447071893351,
      "eval_loss": 0.39762696623802185,
      "eval_runtime": 146.4762,
      "eval_samples_per_second": 123.406,
      "eval_steps_per_second": 15.429,
      "step": 18000
    },
    {
      "epoch": 1.4362799555626091,
      "grad_norm": 0.14128780364990234,
      "learning_rate": 0.0005221951477910795,
      "loss": 0.0109,
      "step": 18100
    },
    {
      "epoch": 1.444215203935883,
      "grad_norm": 0.9885971546173096,
      "learning_rate": 0.0005195465621358195,
      "loss": 0.0071,
      "step": 18200
    },
    {
      "epoch": 1.4521504523091573,
      "grad_norm": 0.37077754735946655,
      "learning_rate": 0.0005168979764805594,
      "loss": 0.0102,
      "step": 18300
    },
    {
      "epoch": 1.4600857006824315,
      "grad_norm": 0.02624533325433731,
      "learning_rate": 0.0005142758766818519,
      "loss": 0.0066,
      "step": 18400
    },
    {
      "epoch": 1.4680209490557055,
      "grad_norm": 0.007569412235170603,
      "learning_rate": 0.0005116272910265918,
      "loss": 0.011,
      "step": 18500
    },
    {
      "epoch": 1.4759561974289794,
      "grad_norm": 0.008227766491472721,
      "learning_rate": 0.0005089787053713318,
      "loss": 0.0109,
      "step": 18600
    },
    {
      "epoch": 1.4838914458022536,
      "grad_norm": 0.15800726413726807,
      "learning_rate": 0.0005063301197160717,
      "loss": 0.0109,
      "step": 18700
    },
    {
      "epoch": 1.4918266941755278,
      "grad_norm": 0.008416115306317806,
      "learning_rate": 0.0005036815340608115,
      "loss": 0.0078,
      "step": 18800
    },
    {
      "epoch": 1.4997619425488018,
      "grad_norm": 0.46446946263313293,
      "learning_rate": 0.0005010329484055515,
      "loss": 0.0111,
      "step": 18900
    },
    {
      "epoch": 1.5076971909220758,
      "grad_norm": 0.061107322573661804,
      "learning_rate": 0.0004983843627502913,
      "loss": 0.0094,
      "step": 19000
    },
    {
      "epoch": 1.5076971909220758,
      "eval_loss": 0.4108946919441223,
      "eval_runtime": 145.778,
      "eval_samples_per_second": 123.997,
      "eval_steps_per_second": 15.503,
      "step": 19000
    },
    {
      "epoch": 1.51563243929535,
      "grad_norm": 0.006412181071937084,
      "learning_rate": 0.0004957357770950313,
      "loss": 0.0099,
      "step": 19100
    },
    {
      "epoch": 1.5235676876686242,
      "grad_norm": 0.07046778500080109,
      "learning_rate": 0.0004930871914397712,
      "loss": 0.0063,
      "step": 19200
    },
    {
      "epoch": 1.5315029360418981,
      "grad_norm": 1.0309226512908936,
      "learning_rate": 0.0004904386057845111,
      "loss": 0.008,
      "step": 19300
    },
    {
      "epoch": 1.539438184415172,
      "grad_norm": 2.3644468784332275,
      "learning_rate": 0.000487790020129251,
      "loss": 0.0097,
      "step": 19400
    },
    {
      "epoch": 1.5473734327884463,
      "grad_norm": 3.6039304733276367,
      "learning_rate": 0.0004851414344739909,
      "loss": 0.0124,
      "step": 19500
    },
    {
      "epoch": 1.5553086811617205,
      "grad_norm": 0.023281127214431763,
      "learning_rate": 0.0004824928488187308,
      "loss": 0.0061,
      "step": 19600
    },
    {
      "epoch": 1.5632439295349945,
      "grad_norm": 0.1126541793346405,
      "learning_rate": 0.0004798442631634707,
      "loss": 0.0087,
      "step": 19700
    },
    {
      "epoch": 1.5711791779082684,
      "grad_norm": 0.3778066635131836,
      "learning_rate": 0.00047719567750821064,
      "loss": 0.0118,
      "step": 19800
    },
    {
      "epoch": 1.5791144262815426,
      "grad_norm": 0.09029284864664078,
      "learning_rate": 0.0004745470918529505,
      "loss": 0.0101,
      "step": 19900
    },
    {
      "epoch": 1.5870496746548168,
      "grad_norm": 0.020432693883776665,
      "learning_rate": 0.0004718985061976904,
      "loss": 0.0069,
      "step": 20000
    },
    {
      "epoch": 1.5870496746548168,
      "eval_loss": 0.3925420343875885,
      "eval_runtime": 144.3977,
      "eval_samples_per_second": 125.182,
      "eval_steps_per_second": 15.651,
      "step": 20000
    },
    {
      "epoch": 1.5949849230280908,
      "grad_norm": 0.606378436088562,
      "learning_rate": 0.0004692499205424304,
      "loss": 0.0116,
      "step": 20100
    },
    {
      "epoch": 1.6029201714013648,
      "grad_norm": 0.16070345044136047,
      "learning_rate": 0.00046660133488717027,
      "loss": 0.0076,
      "step": 20200
    },
    {
      "epoch": 1.610855419774639,
      "grad_norm": 1.5409456491470337,
      "learning_rate": 0.0004639527492319102,
      "loss": 0.0081,
      "step": 20300
    },
    {
      "epoch": 1.6187906681479132,
      "grad_norm": 0.009331835433840752,
      "learning_rate": 0.00046130416357665006,
      "loss": 0.0086,
      "step": 20400
    },
    {
      "epoch": 1.6267259165211871,
      "grad_norm": 0.01937822252511978,
      "learning_rate": 0.00045865557792139003,
      "loss": 0.0133,
      "step": 20500
    },
    {
      "epoch": 1.6346611648944611,
      "grad_norm": 0.120881088078022,
      "learning_rate": 0.00045603347812268245,
      "loss": 0.013,
      "step": 20600
    },
    {
      "epoch": 1.6425964132677353,
      "grad_norm": 0.00738627091050148,
      "learning_rate": 0.00045338489246742243,
      "loss": 0.0089,
      "step": 20700
    },
    {
      "epoch": 1.6505316616410095,
      "grad_norm": 0.8062362670898438,
      "learning_rate": 0.00045073630681216235,
      "loss": 0.007,
      "step": 20800
    },
    {
      "epoch": 1.6584669100142835,
      "grad_norm": 0.09615255147218704,
      "learning_rate": 0.0004480877211569022,
      "loss": 0.0086,
      "step": 20900
    },
    {
      "epoch": 1.6664021583875575,
      "grad_norm": 2.3677380084991455,
      "learning_rate": 0.00044543913550164214,
      "loss": 0.0112,
      "step": 21000
    },
    {
      "epoch": 1.6664021583875575,
      "eval_loss": 0.3940616250038147,
      "eval_runtime": 145.3165,
      "eval_samples_per_second": 124.391,
      "eval_steps_per_second": 15.552,
      "step": 21000
    },
    {
      "epoch": 1.6743374067608316,
      "grad_norm": 0.05645182356238365,
      "learning_rate": 0.00044279054984638206,
      "loss": 0.0047,
      "step": 21100
    },
    {
      "epoch": 1.6822726551341058,
      "grad_norm": 0.15912063419818878,
      "learning_rate": 0.000440141964191122,
      "loss": 0.0073,
      "step": 21200
    },
    {
      "epoch": 1.6902079035073798,
      "grad_norm": 0.010636990889906883,
      "learning_rate": 0.00043749337853586184,
      "loss": 0.0063,
      "step": 21300
    },
    {
      "epoch": 1.6981431518806538,
      "grad_norm": 0.055382344871759415,
      "learning_rate": 0.00043484479288060176,
      "loss": 0.0076,
      "step": 21400
    },
    {
      "epoch": 1.706078400253928,
      "grad_norm": 0.012174472212791443,
      "learning_rate": 0.0004321962072253417,
      "loss": 0.009,
      "step": 21500
    },
    {
      "epoch": 1.7140136486272022,
      "grad_norm": 0.04639868438243866,
      "learning_rate": 0.0004295476215700816,
      "loss": 0.0095,
      "step": 21600
    },
    {
      "epoch": 1.7219488970004762,
      "grad_norm": 0.2055516093969345,
      "learning_rate": 0.00042689903591482147,
      "loss": 0.0064,
      "step": 21700
    },
    {
      "epoch": 1.7298841453737501,
      "grad_norm": 0.011543210595846176,
      "learning_rate": 0.0004242504502595614,
      "loss": 0.0085,
      "step": 21800
    },
    {
      "epoch": 1.7378193937470243,
      "grad_norm": 0.2790558338165283,
      "learning_rate": 0.0004216018646043013,
      "loss": 0.0052,
      "step": 21900
    },
    {
      "epoch": 1.7457546421202985,
      "grad_norm": 0.03673793748021126,
      "learning_rate": 0.00041895327894904123,
      "loss": 0.0045,
      "step": 22000
    },
    {
      "epoch": 1.7457546421202985,
      "eval_loss": 0.4063403308391571,
      "eval_runtime": 143.0967,
      "eval_samples_per_second": 126.32,
      "eval_steps_per_second": 15.794,
      "step": 22000
    },
    {
      "epoch": 1.7536898904935725,
      "grad_norm": 0.02594258449971676,
      "learning_rate": 0.0004163046932937811,
      "loss": 0.0097,
      "step": 22100
    },
    {
      "epoch": 1.7616251388668465,
      "grad_norm": 0.2723715603351593,
      "learning_rate": 0.000413656107638521,
      "loss": 0.0048,
      "step": 22200
    },
    {
      "epoch": 1.7695603872401207,
      "grad_norm": 0.18751415610313416,
      "learning_rate": 0.000411007521983261,
      "loss": 0.0082,
      "step": 22300
    },
    {
      "epoch": 1.7774956356133949,
      "grad_norm": 0.01737045682966709,
      "learning_rate": 0.00040835893632800086,
      "loss": 0.0048,
      "step": 22400
    },
    {
      "epoch": 1.7854308839866688,
      "grad_norm": 0.063356414437294,
      "learning_rate": 0.0004057103506727408,
      "loss": 0.0055,
      "step": 22500
    },
    {
      "epoch": 1.7933661323599428,
      "grad_norm": 0.0035124269779771566,
      "learning_rate": 0.00040306176501748065,
      "loss": 0.0066,
      "step": 22600
    },
    {
      "epoch": 1.801301380733217,
      "grad_norm": 0.13710340857505798,
      "learning_rate": 0.0004004131793622206,
      "loss": 0.0065,
      "step": 22700
    },
    {
      "epoch": 1.8092366291064912,
      "grad_norm": 0.13959772884845734,
      "learning_rate": 0.0003977645937069605,
      "loss": 0.0076,
      "step": 22800
    },
    {
      "epoch": 1.8171718774797652,
      "grad_norm": 0.010999905876815319,
      "learning_rate": 0.0003951160080517004,
      "loss": 0.0073,
      "step": 22900
    },
    {
      "epoch": 1.8251071258530391,
      "grad_norm": 0.009813147597014904,
      "learning_rate": 0.0003924674223964403,
      "loss": 0.0055,
      "step": 23000
    },
    {
      "epoch": 1.8251071258530391,
      "eval_loss": 0.3974798619747162,
      "eval_runtime": 144.0965,
      "eval_samples_per_second": 125.444,
      "eval_steps_per_second": 15.684,
      "step": 23000
    },
    {
      "epoch": 1.8330423742263133,
      "grad_norm": 0.0030540144070982933,
      "learning_rate": 0.00038981883674118025,
      "loss": 0.009,
      "step": 23100
    },
    {
      "epoch": 1.8409776225995875,
      "grad_norm": 0.03942788019776344,
      "learning_rate": 0.00038719673694247273,
      "loss": 0.0059,
      "step": 23200
    },
    {
      "epoch": 1.8489128709728615,
      "grad_norm": 0.051457375288009644,
      "learning_rate": 0.00038454815128721265,
      "loss": 0.0085,
      "step": 23300
    },
    {
      "epoch": 1.8568481193461355,
      "grad_norm": 0.007633883506059647,
      "learning_rate": 0.00038189956563195257,
      "loss": 0.0076,
      "step": 23400
    },
    {
      "epoch": 1.8647833677194097,
      "grad_norm": 0.0036743469536304474,
      "learning_rate": 0.00037925097997669244,
      "loss": 0.0035,
      "step": 23500
    },
    {
      "epoch": 1.8727186160926839,
      "grad_norm": 0.012492968700826168,
      "learning_rate": 0.00037660239432143236,
      "loss": 0.0071,
      "step": 23600
    },
    {
      "epoch": 1.8806538644659578,
      "grad_norm": 0.02528011053800583,
      "learning_rate": 0.0003739538086661723,
      "loss": 0.0035,
      "step": 23700
    },
    {
      "epoch": 1.8885891128392318,
      "grad_norm": 0.027557767927646637,
      "learning_rate": 0.0003713052230109122,
      "loss": 0.0053,
      "step": 23800
    },
    {
      "epoch": 1.896524361212506,
      "grad_norm": 0.6134176254272461,
      "learning_rate": 0.00036865663735565206,
      "loss": 0.0081,
      "step": 23900
    },
    {
      "epoch": 1.9044596095857802,
      "grad_norm": 0.04932962730526924,
      "learning_rate": 0.000366008051700392,
      "loss": 0.0055,
      "step": 24000
    },
    {
      "epoch": 1.9044596095857802,
      "eval_loss": 0.3884682059288025,
      "eval_runtime": 142.9913,
      "eval_samples_per_second": 126.413,
      "eval_steps_per_second": 15.805,
      "step": 24000
    },
    {
      "epoch": 1.9123948579590542,
      "grad_norm": 0.19359299540519714,
      "learning_rate": 0.0003633594660451319,
      "loss": 0.0103,
      "step": 24100
    },
    {
      "epoch": 1.9203301063323281,
      "grad_norm": 0.01468680240213871,
      "learning_rate": 0.0003607108803898718,
      "loss": 0.0047,
      "step": 24200
    },
    {
      "epoch": 1.9282653547056023,
      "grad_norm": 0.0073891920037567616,
      "learning_rate": 0.0003580622947346117,
      "loss": 0.0076,
      "step": 24300
    },
    {
      "epoch": 1.9362006030788763,
      "grad_norm": 0.25821423530578613,
      "learning_rate": 0.0003554137090793516,
      "loss": 0.0044,
      "step": 24400
    },
    {
      "epoch": 1.9441358514521503,
      "grad_norm": 0.014994371682405472,
      "learning_rate": 0.0003527651234240916,
      "loss": 0.0059,
      "step": 24500
    },
    {
      "epoch": 1.9520710998254245,
      "grad_norm": 0.02357935532927513,
      "learning_rate": 0.00035011653776883145,
      "loss": 0.0043,
      "step": 24600
    },
    {
      "epoch": 1.9600063481986987,
      "grad_norm": 0.010625740513205528,
      "learning_rate": 0.0003474679521135714,
      "loss": 0.0067,
      "step": 24700
    },
    {
      "epoch": 1.9679415965719727,
      "grad_norm": 0.111161008477211,
      "learning_rate": 0.00034481936645831124,
      "loss": 0.0035,
      "step": 24800
    },
    {
      "epoch": 1.9758768449452466,
      "grad_norm": 0.010965296998620033,
      "learning_rate": 0.0003421707808030512,
      "loss": 0.0103,
      "step": 24900
    },
    {
      "epoch": 1.9838120933185208,
      "grad_norm": 0.0022062272764742374,
      "learning_rate": 0.0003395221951477911,
      "loss": 0.0106,
      "step": 25000
    },
    {
      "epoch": 1.9838120933185208,
      "eval_loss": 0.4000718295574188,
      "eval_runtime": 147.6475,
      "eval_samples_per_second": 122.427,
      "eval_steps_per_second": 15.307,
      "step": 25000
    },
    {
      "epoch": 1.991747341691795,
      "grad_norm": 0.003170073963701725,
      "learning_rate": 0.000336873609492531,
      "loss": 0.0047,
      "step": 25100
    },
    {
      "epoch": 1.999682590065069,
      "grad_norm": 0.004889748990535736,
      "learning_rate": 0.00033422502383727087,
      "loss": 0.0042,
      "step": 25200
    },
    {
      "epoch": 2.007617838438343,
      "grad_norm": 0.011659301817417145,
      "learning_rate": 0.00033157643818201084,
      "loss": 0.0064,
      "step": 25300
    },
    {
      "epoch": 2.015553086811617,
      "grad_norm": 0.013181311078369617,
      "learning_rate": 0.0003289278525267507,
      "loss": 0.0081,
      "step": 25400
    },
    {
      "epoch": 2.0234883351848914,
      "grad_norm": 0.010876777581870556,
      "learning_rate": 0.00032627926687149063,
      "loss": 0.0058,
      "step": 25500
    },
    {
      "epoch": 2.0314235835581655,
      "grad_norm": 0.005734889768064022,
      "learning_rate": 0.0003236306812162305,
      "loss": 0.0039,
      "step": 25600
    },
    {
      "epoch": 2.0393588319314393,
      "grad_norm": 0.007837483659386635,
      "learning_rate": 0.00032098209556097047,
      "loss": 0.0022,
      "step": 25700
    },
    {
      "epoch": 2.0472940803047135,
      "grad_norm": 0.015702642500400543,
      "learning_rate": 0.00031833350990571034,
      "loss": 0.0024,
      "step": 25800
    },
    {
      "epoch": 2.0552293286779877,
      "grad_norm": 0.003810541471466422,
      "learning_rate": 0.00031568492425045026,
      "loss": 0.0021,
      "step": 25900
    },
    {
      "epoch": 2.063164577051262,
      "grad_norm": 0.010256356559693813,
      "learning_rate": 0.0003130363385951902,
      "loss": 0.004,
      "step": 26000
    },
    {
      "epoch": 2.063164577051262,
      "eval_loss": 0.4146556258201599,
      "eval_runtime": 145.1387,
      "eval_samples_per_second": 124.543,
      "eval_steps_per_second": 15.571,
      "step": 26000
    },
    {
      "epoch": 2.0710998254245356,
      "grad_norm": 1.0400646924972534,
      "learning_rate": 0.0003103877529399301,
      "loss": 0.003,
      "step": 26100
    },
    {
      "epoch": 2.07903507379781,
      "grad_norm": 0.000807266216725111,
      "learning_rate": 0.00030773916728467,
      "loss": 0.0043,
      "step": 26200
    },
    {
      "epoch": 2.086970322171084,
      "grad_norm": 1.1543171405792236,
      "learning_rate": 0.0003050905816294099,
      "loss": 0.0022,
      "step": 26300
    },
    {
      "epoch": 2.094905570544358,
      "grad_norm": 0.12764199078083038,
      "learning_rate": 0.0003024419959741498,
      "loss": 0.0058,
      "step": 26400
    },
    {
      "epoch": 2.102840818917632,
      "grad_norm": 0.0019132046727463603,
      "learning_rate": 0.0002997934103188897,
      "loss": 0.0032,
      "step": 26500
    },
    {
      "epoch": 2.110776067290906,
      "grad_norm": 0.4331265985965729,
      "learning_rate": 0.00029714482466362965,
      "loss": 0.0043,
      "step": 26600
    },
    {
      "epoch": 2.1187113156641804,
      "grad_norm": 0.006693392526358366,
      "learning_rate": 0.0002944962390083695,
      "loss": 0.0041,
      "step": 26700
    },
    {
      "epoch": 2.1266465640374546,
      "grad_norm": 0.04938109591603279,
      "learning_rate": 0.00029184765335310943,
      "loss": 0.0025,
      "step": 26800
    },
    {
      "epoch": 2.1345818124107283,
      "grad_norm": 0.00551371555775404,
      "learning_rate": 0.00028919906769784935,
      "loss": 0.0023,
      "step": 26900
    },
    {
      "epoch": 2.1425170607840025,
      "grad_norm": 0.010915647260844707,
      "learning_rate": 0.0002865504820425893,
      "loss": 0.003,
      "step": 27000
    },
    {
      "epoch": 2.1425170607840025,
      "eval_loss": 0.42572006583213806,
      "eval_runtime": 146.8456,
      "eval_samples_per_second": 123.095,
      "eval_steps_per_second": 15.39,
      "step": 27000
    },
    {
      "epoch": 2.1504523091572767,
      "grad_norm": 0.018383482471108437,
      "learning_rate": 0.00028390189638732914,
      "loss": 0.0057,
      "step": 27100
    },
    {
      "epoch": 2.158387557530551,
      "grad_norm": 0.02700270339846611,
      "learning_rate": 0.00028125331073206906,
      "loss": 0.0049,
      "step": 27200
    },
    {
      "epoch": 2.1663228059038246,
      "grad_norm": 0.015971947461366653,
      "learning_rate": 0.000278604725076809,
      "loss": 0.0018,
      "step": 27300
    },
    {
      "epoch": 2.174258054277099,
      "grad_norm": 0.21335674822330475,
      "learning_rate": 0.00027598262527810146,
      "loss": 0.0033,
      "step": 27400
    },
    {
      "epoch": 2.182193302650373,
      "grad_norm": 0.005181949120014906,
      "learning_rate": 0.00027333403962284143,
      "loss": 0.0075,
      "step": 27500
    },
    {
      "epoch": 2.1901285510236472,
      "grad_norm": 0.12139617651700974,
      "learning_rate": 0.0002706854539675813,
      "loss": 0.0061,
      "step": 27600
    },
    {
      "epoch": 2.198063799396921,
      "grad_norm": 0.006108538247644901,
      "learning_rate": 0.0002680368683123212,
      "loss": 0.0023,
      "step": 27700
    },
    {
      "epoch": 2.205999047770195,
      "grad_norm": 0.009429923258721828,
      "learning_rate": 0.0002653882826570611,
      "loss": 0.0018,
      "step": 27800
    },
    {
      "epoch": 2.2139342961434694,
      "grad_norm": 0.08682925254106522,
      "learning_rate": 0.00026273969700180106,
      "loss": 0.0032,
      "step": 27900
    },
    {
      "epoch": 2.2218695445167436,
      "grad_norm": 0.27533966302871704,
      "learning_rate": 0.00026009111134654093,
      "loss": 0.0043,
      "step": 28000
    },
    {
      "epoch": 2.2218695445167436,
      "eval_loss": 0.416385680437088,
      "eval_runtime": 145.3259,
      "eval_samples_per_second": 124.382,
      "eval_steps_per_second": 15.551,
      "step": 28000
    },
    {
      "epoch": 2.2298047928900173,
      "grad_norm": 0.00786592997610569,
      "learning_rate": 0.00025744252569128085,
      "loss": 0.0034,
      "step": 28100
    },
    {
      "epoch": 2.2377400412632915,
      "grad_norm": 0.0102265365421772,
      "learning_rate": 0.00025479394003602077,
      "loss": 0.0016,
      "step": 28200
    },
    {
      "epoch": 2.2456752896365657,
      "grad_norm": 0.01126760896295309,
      "learning_rate": 0.0002521453543807607,
      "loss": 0.0068,
      "step": 28300
    },
    {
      "epoch": 2.2536105380098395,
      "grad_norm": 0.012563465163111687,
      "learning_rate": 0.0002494967687255006,
      "loss": 0.0013,
      "step": 28400
    },
    {
      "epoch": 2.2615457863831137,
      "grad_norm": 0.03814868628978729,
      "learning_rate": 0.0002468481830702405,
      "loss": 0.0031,
      "step": 28500
    },
    {
      "epoch": 2.269481034756388,
      "grad_norm": 0.015589154325425625,
      "learning_rate": 0.0002441995974149804,
      "loss": 0.0018,
      "step": 28600
    },
    {
      "epoch": 2.277416283129662,
      "grad_norm": 0.06270577758550644,
      "learning_rate": 0.0002415510117597203,
      "loss": 0.0037,
      "step": 28700
    },
    {
      "epoch": 2.2853515315029362,
      "grad_norm": 0.02442583627998829,
      "learning_rate": 0.0002389024261044602,
      "loss": 0.0041,
      "step": 28800
    },
    {
      "epoch": 2.29328677987621,
      "grad_norm": 0.003067540470510721,
      "learning_rate": 0.00023625384044920013,
      "loss": 0.0043,
      "step": 28900
    },
    {
      "epoch": 2.301222028249484,
      "grad_norm": 0.007990287616848946,
      "learning_rate": 0.00023360525479394005,
      "loss": 0.0033,
      "step": 29000
    },
    {
      "epoch": 2.301222028249484,
      "eval_loss": 0.4317553639411926,
      "eval_runtime": 144.6147,
      "eval_samples_per_second": 124.994,
      "eval_steps_per_second": 15.628,
      "step": 29000
    },
    {
      "epoch": 2.3091572766227584,
      "grad_norm": 0.00439828634262085,
      "learning_rate": 0.00023095666913867995,
      "loss": 0.0031,
      "step": 29100
    },
    {
      "epoch": 2.317092524996032,
      "grad_norm": 0.00353728118352592,
      "learning_rate": 0.00022830808348341987,
      "loss": 0.0025,
      "step": 29200
    },
    {
      "epoch": 2.3250277733693063,
      "grad_norm": 0.024266138672828674,
      "learning_rate": 0.00022565949782815976,
      "loss": 0.0037,
      "step": 29300
    },
    {
      "epoch": 2.3329630217425805,
      "grad_norm": 0.004525026772171259,
      "learning_rate": 0.00022301091217289968,
      "loss": 0.0049,
      "step": 29400
    },
    {
      "epoch": 2.3408982701158547,
      "grad_norm": 0.02402411587536335,
      "learning_rate": 0.00022036232651763957,
      "loss": 0.0049,
      "step": 29500
    },
    {
      "epoch": 2.348833518489129,
      "grad_norm": 0.024534743279218674,
      "learning_rate": 0.0002177137408623795,
      "loss": 0.0033,
      "step": 29600
    },
    {
      "epoch": 2.3567687668624027,
      "grad_norm": 0.007585424929857254,
      "learning_rate": 0.0002150651552071194,
      "loss": 0.0043,
      "step": 29700
    },
    {
      "epoch": 2.364704015235677,
      "grad_norm": 0.0018416885286569595,
      "learning_rate": 0.0002124165695518593,
      "loss": 0.0028,
      "step": 29800
    },
    {
      "epoch": 2.372639263608951,
      "grad_norm": 0.004332641139626503,
      "learning_rate": 0.0002097679838965992,
      "loss": 0.0072,
      "step": 29900
    },
    {
      "epoch": 2.380574511982225,
      "grad_norm": 0.005708771757781506,
      "learning_rate": 0.00020711939824133912,
      "loss": 0.0033,
      "step": 30000
    },
    {
      "epoch": 2.380574511982225,
      "eval_loss": 0.4171780049800873,
      "eval_runtime": 142.7582,
      "eval_samples_per_second": 126.62,
      "eval_steps_per_second": 15.831,
      "step": 30000
    },
    {
      "epoch": 2.388509760355499,
      "grad_norm": 0.04391546547412872,
      "learning_rate": 0.00020447081258607902,
      "loss": 0.0011,
      "step": 30100
    },
    {
      "epoch": 2.396445008728773,
      "grad_norm": 0.00870323833078146,
      "learning_rate": 0.00020184871278737155,
      "loss": 0.0041,
      "step": 30200
    },
    {
      "epoch": 2.4043802571020474,
      "grad_norm": 0.009954049251973629,
      "learning_rate": 0.00019920012713211147,
      "loss": 0.0021,
      "step": 30300
    },
    {
      "epoch": 2.4123155054753216,
      "grad_norm": 1.8491207361221313,
      "learning_rate": 0.00019655154147685136,
      "loss": 0.0031,
      "step": 30400
    },
    {
      "epoch": 2.4202507538485953,
      "grad_norm": 0.00763834360986948,
      "learning_rate": 0.00019390295582159128,
      "loss": 0.0048,
      "step": 30500
    },
    {
      "epoch": 2.4281860022218695,
      "grad_norm": 0.00662822462618351,
      "learning_rate": 0.00019125437016633118,
      "loss": 0.0026,
      "step": 30600
    },
    {
      "epoch": 2.4361212505951437,
      "grad_norm": 0.005041108932346106,
      "learning_rate": 0.0001886057845110711,
      "loss": 0.0013,
      "step": 30700
    },
    {
      "epoch": 2.4440564989684175,
      "grad_norm": 0.019155755639076233,
      "learning_rate": 0.000185957198855811,
      "loss": 0.0019,
      "step": 30800
    },
    {
      "epoch": 2.4519917473416917,
      "grad_norm": 0.0067033180966973305,
      "learning_rate": 0.0001833086132005509,
      "loss": 0.0048,
      "step": 30900
    },
    {
      "epoch": 2.459926995714966,
      "grad_norm": 0.02266606129705906,
      "learning_rate": 0.0001806600275452908,
      "loss": 0.003,
      "step": 31000
    },
    {
      "epoch": 2.459926995714966,
      "eval_loss": 0.4157598912715912,
      "eval_runtime": 152.1594,
      "eval_samples_per_second": 118.796,
      "eval_steps_per_second": 14.853,
      "step": 31000
    },
    {
      "epoch": 2.46786224408824,
      "grad_norm": 0.08016986399888992,
      "learning_rate": 0.00017801144189003075,
      "loss": 0.0019,
      "step": 31100
    },
    {
      "epoch": 2.4757974924615143,
      "grad_norm": 0.09564433246850967,
      "learning_rate": 0.00017536285623477065,
      "loss": 0.0016,
      "step": 31200
    },
    {
      "epoch": 2.483732740834788,
      "grad_norm": 0.009883185848593712,
      "learning_rate": 0.00017271427057951057,
      "loss": 0.0045,
      "step": 31300
    },
    {
      "epoch": 2.491667989208062,
      "grad_norm": 0.012320149689912796,
      "learning_rate": 0.00017006568492425046,
      "loss": 0.0018,
      "step": 31400
    },
    {
      "epoch": 2.4996032375813364,
      "grad_norm": 0.11542996764183044,
      "learning_rate": 0.00016741709926899038,
      "loss": 0.0036,
      "step": 31500
    },
    {
      "epoch": 2.50753848595461,
      "grad_norm": 0.002601372543722391,
      "learning_rate": 0.00016476851361373027,
      "loss": 0.0018,
      "step": 31600
    },
    {
      "epoch": 2.5154737343278843,
      "grad_norm": 0.003249931847676635,
      "learning_rate": 0.0001621199279584702,
      "loss": 0.0007,
      "step": 31700
    },
    {
      "epoch": 2.5234089827011585,
      "grad_norm": 0.06684944033622742,
      "learning_rate": 0.0001594713423032101,
      "loss": 0.001,
      "step": 31800
    },
    {
      "epoch": 2.5313442310744327,
      "grad_norm": 0.07922570407390594,
      "learning_rate": 0.00015682275664795,
      "loss": 0.0022,
      "step": 31900
    },
    {
      "epoch": 2.539279479447707,
      "grad_norm": 0.06186359375715256,
      "learning_rate": 0.0001541741709926899,
      "loss": 0.0012,
      "step": 32000
    },
    {
      "epoch": 2.539279479447707,
      "eval_loss": 0.4179616868495941,
      "eval_runtime": 153.6596,
      "eval_samples_per_second": 117.637,
      "eval_steps_per_second": 14.708,
      "step": 32000
    },
    {
      "epoch": 2.5472147278209807,
      "grad_norm": 0.16977240145206451,
      "learning_rate": 0.00015152558533742982,
      "loss": 0.0057,
      "step": 32100
    },
    {
      "epoch": 2.555149976194255,
      "grad_norm": 0.009013823233544827,
      "learning_rate": 0.00014887699968216972,
      "loss": 0.002,
      "step": 32200
    },
    {
      "epoch": 2.563085224567529,
      "grad_norm": 0.07603202015161514,
      "learning_rate": 0.00014622841402690964,
      "loss": 0.0017,
      "step": 32300
    },
    {
      "epoch": 2.571020472940803,
      "grad_norm": 0.05749272555112839,
      "learning_rate": 0.00014357982837164953,
      "loss": 0.003,
      "step": 32400
    },
    {
      "epoch": 2.578955721314077,
      "grad_norm": 0.033829815685749054,
      "learning_rate": 0.00014093124271638945,
      "loss": 0.0018,
      "step": 32500
    },
    {
      "epoch": 2.586890969687351,
      "grad_norm": 0.41251105070114136,
      "learning_rate": 0.00013828265706112937,
      "loss": 0.002,
      "step": 32600
    },
    {
      "epoch": 2.5948262180606254,
      "grad_norm": 0.003620849922299385,
      "learning_rate": 0.0001356340714058693,
      "loss": 0.0009,
      "step": 32700
    },
    {
      "epoch": 2.6027614664338996,
      "grad_norm": 0.038926076143980026,
      "learning_rate": 0.00013298548575060918,
      "loss": 0.0023,
      "step": 32800
    },
    {
      "epoch": 2.6106967148071734,
      "grad_norm": 0.004034352954477072,
      "learning_rate": 0.0001303369000953491,
      "loss": 0.0005,
      "step": 32900
    },
    {
      "epoch": 2.6186319631804476,
      "grad_norm": 0.07644424587488174,
      "learning_rate": 0.000127688314440089,
      "loss": 0.0038,
      "step": 33000
    },
    {
      "epoch": 2.6186319631804476,
      "eval_loss": 0.42887991666793823,
      "eval_runtime": 153.2516,
      "eval_samples_per_second": 117.95,
      "eval_steps_per_second": 14.747,
      "step": 33000
    },
    {
      "epoch": 2.6265672115537217,
      "grad_norm": 0.0029484552796930075,
      "learning_rate": 0.00012503972878482892,
      "loss": 0.0022,
      "step": 33100
    },
    {
      "epoch": 2.6345024599269955,
      "grad_norm": 0.06166280806064606,
      "learning_rate": 0.0001223911431295688,
      "loss": 0.0009,
      "step": 33200
    },
    {
      "epoch": 2.6424377083002697,
      "grad_norm": 0.0028269824106246233,
      "learning_rate": 0.00011974255747430872,
      "loss": 0.0022,
      "step": 33300
    },
    {
      "epoch": 2.650372956673544,
      "grad_norm": 0.06551153212785721,
      "learning_rate": 0.00011709397181904863,
      "loss": 0.0012,
      "step": 33400
    },
    {
      "epoch": 2.658308205046818,
      "grad_norm": 0.010463287122547626,
      "learning_rate": 0.00011444538616378853,
      "loss": 0.0025,
      "step": 33500
    },
    {
      "epoch": 2.6662434534200923,
      "grad_norm": 0.022524237632751465,
      "learning_rate": 0.00011179680050852844,
      "loss": 0.0019,
      "step": 33600
    },
    {
      "epoch": 2.674178701793366,
      "grad_norm": 0.0044563584960997105,
      "learning_rate": 0.00010914821485326835,
      "loss": 0.004,
      "step": 33700
    },
    {
      "epoch": 2.6821139501666402,
      "grad_norm": 0.0012104215566068888,
      "learning_rate": 0.00010649962919800827,
      "loss": 0.0008,
      "step": 33800
    },
    {
      "epoch": 2.6900491985399144,
      "grad_norm": 0.0019163445103913546,
      "learning_rate": 0.00010385104354274818,
      "loss": 0.0029,
      "step": 33900
    },
    {
      "epoch": 2.697984446913188,
      "grad_norm": 0.001736812642775476,
      "learning_rate": 0.00010120245788748808,
      "loss": 0.0015,
      "step": 34000
    },
    {
      "epoch": 2.697984446913188,
      "eval_loss": 0.4287972152233124,
      "eval_runtime": 153.0588,
      "eval_samples_per_second": 118.098,
      "eval_steps_per_second": 14.766,
      "step": 34000
    },
    {
      "epoch": 2.7059196952864624,
      "grad_norm": 0.0017710509710013866,
      "learning_rate": 9.855387223222799e-05,
      "loss": 0.0021,
      "step": 34100
    },
    {
      "epoch": 2.7138549436597366,
      "grad_norm": 0.03888317197561264,
      "learning_rate": 9.59317724335205e-05,
      "loss": 0.0024,
      "step": 34200
    },
    {
      "epoch": 2.7217901920330108,
      "grad_norm": 0.0008137364056892693,
      "learning_rate": 9.330967263481301e-05,
      "loss": 0.0008,
      "step": 34300
    },
    {
      "epoch": 2.729725440406285,
      "grad_norm": 0.013438007794320583,
      "learning_rate": 9.066108697955292e-05,
      "loss": 0.0066,
      "step": 34400
    },
    {
      "epoch": 2.7376606887795587,
      "grad_norm": 1.1648571491241455,
      "learning_rate": 8.801250132429283e-05,
      "loss": 0.0032,
      "step": 34500
    },
    {
      "epoch": 2.745595937152833,
      "grad_norm": 0.005597705487161875,
      "learning_rate": 8.536391566903273e-05,
      "loss": 0.0029,
      "step": 34600
    },
    {
      "epoch": 2.753531185526107,
      "grad_norm": 0.002318794373422861,
      "learning_rate": 8.271533001377264e-05,
      "loss": 0.003,
      "step": 34700
    },
    {
      "epoch": 2.761466433899381,
      "grad_norm": 0.0349833145737648,
      "learning_rate": 8.006674435851255e-05,
      "loss": 0.0044,
      "step": 34800
    },
    {
      "epoch": 2.769401682272655,
      "grad_norm": 3.78084397315979,
      "learning_rate": 7.741815870325245e-05,
      "loss": 0.0053,
      "step": 34900
    },
    {
      "epoch": 2.7773369306459292,
      "grad_norm": 0.14856375753879547,
      "learning_rate": 7.476957304799236e-05,
      "loss": 0.0017,
      "step": 35000
    },
    {
      "epoch": 2.7773369306459292,
      "eval_loss": 0.43800851702690125,
      "eval_runtime": 152.3186,
      "eval_samples_per_second": 118.672,
      "eval_steps_per_second": 14.837,
      "step": 35000
    },
    {
      "epoch": 2.7852721790192034,
      "grad_norm": 0.004835879430174828,
      "learning_rate": 7.212098739273228e-05,
      "loss": 0.0032,
      "step": 35100
    },
    {
      "epoch": 2.7932074273924776,
      "grad_norm": 0.0155509477481246,
      "learning_rate": 6.947240173747219e-05,
      "loss": 0.0034,
      "step": 35200
    },
    {
      "epoch": 2.8011426757657514,
      "grad_norm": 0.01676555536687374,
      "learning_rate": 6.68238160822121e-05,
      "loss": 0.0036,
      "step": 35300
    },
    {
      "epoch": 2.8090779241390256,
      "grad_norm": 0.0018051884835585952,
      "learning_rate": 6.4175230426952e-05,
      "loss": 0.0026,
      "step": 35400
    },
    {
      "epoch": 2.8170131725122998,
      "grad_norm": 0.008900467306375504,
      "learning_rate": 6.152664477169192e-05,
      "loss": 0.0069,
      "step": 35500
    },
    {
      "epoch": 2.8249484208855735,
      "grad_norm": 0.001946846256032586,
      "learning_rate": 5.887805911643183e-05,
      "loss": 0.0029,
      "step": 35600
    },
    {
      "epoch": 2.8328836692588477,
      "grad_norm": 0.0031805592589080334,
      "learning_rate": 5.622947346117174e-05,
      "loss": 0.0006,
      "step": 35700
    },
    {
      "epoch": 2.840818917632122,
      "grad_norm": 0.002768539823591709,
      "learning_rate": 5.3580887805911644e-05,
      "loss": 0.0039,
      "step": 35800
    },
    {
      "epoch": 2.848754166005396,
      "grad_norm": 2.137275457382202,
      "learning_rate": 5.093230215065155e-05,
      "loss": 0.0006,
      "step": 35900
    },
    {
      "epoch": 2.8566894143786703,
      "grad_norm": 0.004198015667498112,
      "learning_rate": 4.8283716495391465e-05,
      "loss": 0.0009,
      "step": 36000
    },
    {
      "epoch": 2.8566894143786703,
      "eval_loss": 0.43009576201438904,
      "eval_runtime": 148.4497,
      "eval_samples_per_second": 121.765,
      "eval_steps_per_second": 15.224,
      "step": 36000
    },
    {
      "epoch": 2.864624662751944,
      "grad_norm": 0.016869395971298218,
      "learning_rate": 4.563513084013137e-05,
      "loss": 0.0004,
      "step": 36100
    },
    {
      "epoch": 2.8725599111252182,
      "grad_norm": 0.0042915139347314835,
      "learning_rate": 4.298654518487128e-05,
      "loss": 0.0005,
      "step": 36200
    },
    {
      "epoch": 2.8804951594984924,
      "grad_norm": 0.009384104050695896,
      "learning_rate": 4.0337959529611186e-05,
      "loss": 0.0017,
      "step": 36300
    },
    {
      "epoch": 2.888430407871766,
      "grad_norm": 0.015485461801290512,
      "learning_rate": 3.76893738743511e-05,
      "loss": 0.0013,
      "step": 36400
    },
    {
      "epoch": 2.8963656562450404,
      "grad_norm": 0.003953051287680864,
      "learning_rate": 3.504078821909101e-05,
      "loss": 0.0017,
      "step": 36500
    },
    {
      "epoch": 2.9043009046183146,
      "grad_norm": 0.0018613121937960386,
      "learning_rate": 3.2392202563830914e-05,
      "loss": 0.0012,
      "step": 36600
    },
    {
      "epoch": 2.9122361529915888,
      "grad_norm": 0.14006632566452026,
      "learning_rate": 2.9743616908570824e-05,
      "loss": 0.0016,
      "step": 36700
    },
    {
      "epoch": 2.920171401364863,
      "grad_norm": 0.002313799224793911,
      "learning_rate": 2.709503125331073e-05,
      "loss": 0.0004,
      "step": 36800
    },
    {
      "epoch": 2.9281066497381367,
      "grad_norm": 0.009073823690414429,
      "learning_rate": 2.444644559805064e-05,
      "loss": 0.0018,
      "step": 36900
    },
    {
      "epoch": 2.936041898111411,
      "grad_norm": 0.007570577785372734,
      "learning_rate": 2.1797859942790552e-05,
      "loss": 0.0013,
      "step": 37000
    },
    {
      "epoch": 2.936041898111411,
      "eval_loss": 0.43286338448524475,
      "eval_runtime": 157.7579,
      "eval_samples_per_second": 114.581,
      "eval_steps_per_second": 14.326,
      "step": 37000
    }
  ],
  "logging_steps": 100,
  "max_steps": 37806,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.988951814577152e+19,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

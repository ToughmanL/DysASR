{
  "best_metric": 0.3693881332874298,
  "best_model_checkpoint": "output/SpeechAccessibility/whisper-base/checkpoint-12000",
  "epoch": 2.0294266869609334,
  "eval_steps": 1000,
  "global_step": 12000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01691188905800778,
      "grad_norm": 0.4781639575958252,
      "learning_rate": 0.0009973429815139353,
      "loss": 1.847,
      "step": 100
    },
    {
      "epoch": 0.03382377811601556,
      "grad_norm": 0.6735156178474426,
      "learning_rate": 0.0009916897506925208,
      "loss": 0.8043,
      "step": 200
    },
    {
      "epoch": 0.050735667174023336,
      "grad_norm": 0.7429453730583191,
      "learning_rate": 0.0009860365198711063,
      "loss": 0.6995,
      "step": 300
    },
    {
      "epoch": 0.06764755623203111,
      "grad_norm": 0.6333523988723755,
      "learning_rate": 0.0009803832890496918,
      "loss": 0.6412,
      "step": 400
    },
    {
      "epoch": 0.08455944529003889,
      "grad_norm": 0.5673621892929077,
      "learning_rate": 0.0009747300582282774,
      "loss": 0.5825,
      "step": 500
    },
    {
      "epoch": 0.10147133434804667,
      "grad_norm": 0.7016572952270508,
      "learning_rate": 0.0009690768274068631,
      "loss": 0.5623,
      "step": 600
    },
    {
      "epoch": 0.11838322340605445,
      "grad_norm": 0.9304994940757751,
      "learning_rate": 0.0009634235965854486,
      "loss": 0.5521,
      "step": 700
    },
    {
      "epoch": 0.13529511246406223,
      "grad_norm": 1.1190942525863647,
      "learning_rate": 0.0009577703657640342,
      "loss": 0.5361,
      "step": 800
    },
    {
      "epoch": 0.15220700152207,
      "grad_norm": 0.6776029467582703,
      "learning_rate": 0.0009521171349426197,
      "loss": 0.5494,
      "step": 900
    },
    {
      "epoch": 0.16911889058007779,
      "grad_norm": 0.7279991507530212,
      "learning_rate": 0.0009464639041212053,
      "loss": 0.4751,
      "step": 1000
    },
    {
      "epoch": 0.16911889058007779,
      "eval_loss": 0.5878291130065918,
      "eval_runtime": 161.0456,
      "eval_samples_per_second": 125.828,
      "eval_steps_per_second": 15.728,
      "step": 1000
    },
    {
      "epoch": 0.18603077963808556,
      "grad_norm": 0.7553130388259888,
      "learning_rate": 0.0009408106732997909,
      "loss": 0.4765,
      "step": 1100
    },
    {
      "epoch": 0.20294266869609334,
      "grad_norm": 0.7979035377502441,
      "learning_rate": 0.0009351574424783765,
      "loss": 0.4863,
      "step": 1200
    },
    {
      "epoch": 0.21985455775410112,
      "grad_norm": 0.7642136812210083,
      "learning_rate": 0.000929504211656962,
      "loss": 0.4339,
      "step": 1300
    },
    {
      "epoch": 0.2367664468121089,
      "grad_norm": 0.8646769523620605,
      "learning_rate": 0.0009238509808355475,
      "loss": 0.4527,
      "step": 1400
    },
    {
      "epoch": 0.2536783358701167,
      "grad_norm": 0.5033321976661682,
      "learning_rate": 0.0009181977500141331,
      "loss": 0.443,
      "step": 1500
    },
    {
      "epoch": 0.27059022492812446,
      "grad_norm": 1.09914231300354,
      "learning_rate": 0.0009125445191927186,
      "loss": 0.4131,
      "step": 1600
    },
    {
      "epoch": 0.28750211398613224,
      "grad_norm": 1.6048222780227661,
      "learning_rate": 0.0009068912883713042,
      "loss": 0.43,
      "step": 1700
    },
    {
      "epoch": 0.30441400304414,
      "grad_norm": 0.9217829704284668,
      "learning_rate": 0.0009012380575498897,
      "loss": 0.4281,
      "step": 1800
    },
    {
      "epoch": 0.3213258921021478,
      "grad_norm": 0.9580841064453125,
      "learning_rate": 0.0008955848267284753,
      "loss": 0.4299,
      "step": 1900
    },
    {
      "epoch": 0.33823778116015557,
      "grad_norm": 0.6824224591255188,
      "learning_rate": 0.0008899315959070608,
      "loss": 0.3885,
      "step": 2000
    },
    {
      "epoch": 0.33823778116015557,
      "eval_loss": 0.5064615607261658,
      "eval_runtime": 160.5013,
      "eval_samples_per_second": 126.254,
      "eval_steps_per_second": 15.782,
      "step": 2000
    },
    {
      "epoch": 0.35514967021816335,
      "grad_norm": 0.7977136373519897,
      "learning_rate": 0.0008842783650856466,
      "loss": 0.3837,
      "step": 2100
    },
    {
      "epoch": 0.3720615592761711,
      "grad_norm": 0.8641473650932312,
      "learning_rate": 0.0008786251342642321,
      "loss": 0.4091,
      "step": 2200
    },
    {
      "epoch": 0.3889734483341789,
      "grad_norm": 0.8944063186645508,
      "learning_rate": 0.0008729719034428176,
      "loss": 0.3811,
      "step": 2300
    },
    {
      "epoch": 0.4058853373921867,
      "grad_norm": 0.698698103427887,
      "learning_rate": 0.0008673186726214032,
      "loss": 0.3488,
      "step": 2400
    },
    {
      "epoch": 0.42279722645019446,
      "grad_norm": 0.9217584133148193,
      "learning_rate": 0.0008617219741082028,
      "loss": 0.3625,
      "step": 2500
    },
    {
      "epoch": 0.43970911550820224,
      "grad_norm": 1.087981939315796,
      "learning_rate": 0.0008560687432867884,
      "loss": 0.3688,
      "step": 2600
    },
    {
      "epoch": 0.45662100456621,
      "grad_norm": 0.8443595767021179,
      "learning_rate": 0.0008504155124653739,
      "loss": 0.4089,
      "step": 2700
    },
    {
      "epoch": 0.4735328936242178,
      "grad_norm": 1.032946228981018,
      "learning_rate": 0.0008447622816439596,
      "loss": 0.3671,
      "step": 2800
    },
    {
      "epoch": 0.4904447826822256,
      "grad_norm": 0.5757914185523987,
      "learning_rate": 0.0008391090508225451,
      "loss": 0.3452,
      "step": 2900
    },
    {
      "epoch": 0.5073566717402334,
      "grad_norm": 0.8611394166946411,
      "learning_rate": 0.0008334558200011307,
      "loss": 0.3987,
      "step": 3000
    },
    {
      "epoch": 0.5073566717402334,
      "eval_loss": 0.4658414125442505,
      "eval_runtime": 160.9763,
      "eval_samples_per_second": 125.882,
      "eval_steps_per_second": 15.735,
      "step": 3000
    },
    {
      "epoch": 0.5242685607982411,
      "grad_norm": 0.9306372404098511,
      "learning_rate": 0.0008278025891797162,
      "loss": 0.3495,
      "step": 3100
    },
    {
      "epoch": 0.5411804498562489,
      "grad_norm": 1.2415612936019897,
      "learning_rate": 0.0008221493583583017,
      "loss": 0.3572,
      "step": 3200
    },
    {
      "epoch": 0.5580923389142567,
      "grad_norm": 0.8974349498748779,
      "learning_rate": 0.0008164961275368874,
      "loss": 0.3402,
      "step": 3300
    },
    {
      "epoch": 0.5750042279722645,
      "grad_norm": 0.7698546648025513,
      "learning_rate": 0.0008108428967154729,
      "loss": 0.331,
      "step": 3400
    },
    {
      "epoch": 0.5919161170302722,
      "grad_norm": 0.6957382559776306,
      "learning_rate": 0.0008051896658940585,
      "loss": 0.3176,
      "step": 3500
    },
    {
      "epoch": 0.60882800608828,
      "grad_norm": 0.769128680229187,
      "learning_rate": 0.000799536435072644,
      "loss": 0.3094,
      "step": 3600
    },
    {
      "epoch": 0.6257398951462878,
      "grad_norm": 0.9298968315124512,
      "learning_rate": 0.0007938832042512296,
      "loss": 0.3281,
      "step": 3700
    },
    {
      "epoch": 0.6426517842042956,
      "grad_norm": 1.4648027420043945,
      "learning_rate": 0.0007882299734298152,
      "loss": 0.3474,
      "step": 3800
    },
    {
      "epoch": 0.6595636732623034,
      "grad_norm": 0.5213785767555237,
      "learning_rate": 0.0007825767426084008,
      "loss": 0.303,
      "step": 3900
    },
    {
      "epoch": 0.6764755623203111,
      "grad_norm": 0.7404161095619202,
      "learning_rate": 0.0007769235117869863,
      "loss": 0.3222,
      "step": 4000
    },
    {
      "epoch": 0.6764755623203111,
      "eval_loss": 0.441138356924057,
      "eval_runtime": 160.5211,
      "eval_samples_per_second": 126.239,
      "eval_steps_per_second": 15.78,
      "step": 4000
    },
    {
      "epoch": 0.6933874513783189,
      "grad_norm": 1.1469358205795288,
      "learning_rate": 0.0007712702809655719,
      "loss": 0.3229,
      "step": 4100
    },
    {
      "epoch": 0.7102993404363267,
      "grad_norm": 0.9609880447387695,
      "learning_rate": 0.0007656170501441574,
      "loss": 0.3416,
      "step": 4200
    },
    {
      "epoch": 0.7272112294943345,
      "grad_norm": 0.8660038113594055,
      "learning_rate": 0.0007599638193227429,
      "loss": 0.312,
      "step": 4300
    },
    {
      "epoch": 0.7441231185523423,
      "grad_norm": 1.2727800607681274,
      "learning_rate": 0.0007543105885013285,
      "loss": 0.2803,
      "step": 4400
    },
    {
      "epoch": 0.76103500761035,
      "grad_norm": 0.9910476803779602,
      "learning_rate": 0.000748657357679914,
      "loss": 0.3113,
      "step": 4500
    },
    {
      "epoch": 0.7779468966683578,
      "grad_norm": 1.1182018518447876,
      "learning_rate": 0.0007430041268584996,
      "loss": 0.3413,
      "step": 4600
    },
    {
      "epoch": 0.7948587857263656,
      "grad_norm": 0.9646634459495544,
      "learning_rate": 0.0007373508960370851,
      "loss": 0.2725,
      "step": 4700
    },
    {
      "epoch": 0.8117706747843734,
      "grad_norm": 0.6823699474334717,
      "learning_rate": 0.0007316976652156708,
      "loss": 0.3139,
      "step": 4800
    },
    {
      "epoch": 0.8286825638423811,
      "grad_norm": 0.8734323978424072,
      "learning_rate": 0.0007260444343942564,
      "loss": 0.2989,
      "step": 4900
    },
    {
      "epoch": 0.8455944529003889,
      "grad_norm": 0.9640293717384338,
      "learning_rate": 0.000720391203572842,
      "loss": 0.3109,
      "step": 5000
    },
    {
      "epoch": 0.8455944529003889,
      "eval_loss": 0.42472004890441895,
      "eval_runtime": 160.7372,
      "eval_samples_per_second": 126.069,
      "eval_steps_per_second": 15.759,
      "step": 5000
    },
    {
      "epoch": 0.8625063419583967,
      "grad_norm": 1.522341012954712,
      "learning_rate": 0.0007147945050596416,
      "loss": 0.3109,
      "step": 5100
    },
    {
      "epoch": 0.8794182310164045,
      "grad_norm": 0.8341310024261475,
      "learning_rate": 0.0007091412742382271,
      "loss": 0.3247,
      "step": 5200
    },
    {
      "epoch": 0.8963301200744123,
      "grad_norm": 0.5567260384559631,
      "learning_rate": 0.0007034880434168127,
      "loss": 0.2865,
      "step": 5300
    },
    {
      "epoch": 0.91324200913242,
      "grad_norm": 0.8929381966590881,
      "learning_rate": 0.0006978348125953982,
      "loss": 0.2991,
      "step": 5400
    },
    {
      "epoch": 0.9301538981904278,
      "grad_norm": 0.8066146969795227,
      "learning_rate": 0.0006921815817739839,
      "loss": 0.3054,
      "step": 5500
    },
    {
      "epoch": 0.9470657872484356,
      "grad_norm": 0.9478539824485779,
      "learning_rate": 0.0006865283509525694,
      "loss": 0.2758,
      "step": 5600
    },
    {
      "epoch": 0.9639776763064434,
      "grad_norm": 1.0546528100967407,
      "learning_rate": 0.000680875120131155,
      "loss": 0.3555,
      "step": 5700
    },
    {
      "epoch": 0.9808895653644512,
      "grad_norm": 0.9695011973381042,
      "learning_rate": 0.0006752218893097405,
      "loss": 0.2901,
      "step": 5800
    },
    {
      "epoch": 0.9978014544224589,
      "grad_norm": 1.1131353378295898,
      "learning_rate": 0.0006695686584883261,
      "loss": 0.3055,
      "step": 5900
    },
    {
      "epoch": 1.0147133434804667,
      "grad_norm": 0.5071542859077454,
      "learning_rate": 0.0006639154276669117,
      "loss": 0.2676,
      "step": 6000
    },
    {
      "epoch": 1.0147133434804667,
      "eval_loss": 0.4056103527545929,
      "eval_runtime": 159.2043,
      "eval_samples_per_second": 127.283,
      "eval_steps_per_second": 15.91,
      "step": 6000
    },
    {
      "epoch": 1.0316252325384745,
      "grad_norm": 1.1357074975967407,
      "learning_rate": 0.0006582621968454972,
      "loss": 0.1982,
      "step": 6100
    },
    {
      "epoch": 1.0485371215964823,
      "grad_norm": 0.7453293800354004,
      "learning_rate": 0.0006526089660240828,
      "loss": 0.2225,
      "step": 6200
    },
    {
      "epoch": 1.06544901065449,
      "grad_norm": 0.7306705713272095,
      "learning_rate": 0.0006469557352026683,
      "loss": 0.2339,
      "step": 6300
    },
    {
      "epoch": 1.0823608997124978,
      "grad_norm": 0.9768306016921997,
      "learning_rate": 0.000641302504381254,
      "loss": 0.22,
      "step": 6400
    },
    {
      "epoch": 1.0992727887705056,
      "grad_norm": 0.7354117631912231,
      "learning_rate": 0.0006356492735598395,
      "loss": 0.2406,
      "step": 6500
    },
    {
      "epoch": 1.1161846778285134,
      "grad_norm": 0.6312853097915649,
      "learning_rate": 0.0006299960427384251,
      "loss": 0.2099,
      "step": 6600
    },
    {
      "epoch": 1.1330965668865212,
      "grad_norm": 0.9767425656318665,
      "learning_rate": 0.0006243428119170106,
      "loss": 0.2108,
      "step": 6700
    },
    {
      "epoch": 1.150008455944529,
      "grad_norm": 0.743656575679779,
      "learning_rate": 0.0006186895810955962,
      "loss": 0.2107,
      "step": 6800
    },
    {
      "epoch": 1.1669203450025367,
      "grad_norm": 0.5182315111160278,
      "learning_rate": 0.0006130363502741817,
      "loss": 0.2059,
      "step": 6900
    },
    {
      "epoch": 1.1838322340605445,
      "grad_norm": 1.1267246007919312,
      "learning_rate": 0.0006073831194527672,
      "loss": 0.1938,
      "step": 7000
    },
    {
      "epoch": 1.1838322340605445,
      "eval_loss": 0.39896708726882935,
      "eval_runtime": 161.3256,
      "eval_samples_per_second": 125.609,
      "eval_steps_per_second": 15.701,
      "step": 7000
    },
    {
      "epoch": 1.2007441231185523,
      "grad_norm": 1.1471704244613647,
      "learning_rate": 0.0006017298886313528,
      "loss": 0.2094,
      "step": 7100
    },
    {
      "epoch": 1.21765601217656,
      "grad_norm": 0.6128181219100952,
      "learning_rate": 0.0005960766578099383,
      "loss": 0.211,
      "step": 7200
    },
    {
      "epoch": 1.2345679012345678,
      "grad_norm": 0.47655558586120605,
      "learning_rate": 0.0005904234269885239,
      "loss": 0.2388,
      "step": 7300
    },
    {
      "epoch": 1.2514797902925756,
      "grad_norm": 0.9585337042808533,
      "learning_rate": 0.0005847701961671094,
      "loss": 0.2394,
      "step": 7400
    },
    {
      "epoch": 1.2683916793505834,
      "grad_norm": 0.7936450242996216,
      "learning_rate": 0.000579116965345695,
      "loss": 0.2297,
      "step": 7500
    },
    {
      "epoch": 1.2853035684085912,
      "grad_norm": 0.7333446145057678,
      "learning_rate": 0.0005734637345242807,
      "loss": 0.2149,
      "step": 7600
    },
    {
      "epoch": 1.302215457466599,
      "grad_norm": 0.9203324317932129,
      "learning_rate": 0.0005678105037028663,
      "loss": 0.2141,
      "step": 7700
    },
    {
      "epoch": 1.3191273465246067,
      "grad_norm": 0.742976725101471,
      "learning_rate": 0.0005621572728814518,
      "loss": 0.2259,
      "step": 7800
    },
    {
      "epoch": 1.3360392355826145,
      "grad_norm": 1.047446608543396,
      "learning_rate": 0.0005565040420600374,
      "loss": 0.2142,
      "step": 7900
    },
    {
      "epoch": 1.3529511246406223,
      "grad_norm": 0.5963254570960999,
      "learning_rate": 0.0005508508112386229,
      "loss": 0.2126,
      "step": 8000
    },
    {
      "epoch": 1.3529511246406223,
      "eval_loss": 0.3940548002719879,
      "eval_runtime": 161.3556,
      "eval_samples_per_second": 125.586,
      "eval_steps_per_second": 15.698,
      "step": 8000
    },
    {
      "epoch": 1.36986301369863,
      "grad_norm": 1.2599533796310425,
      "learning_rate": 0.0005451975804172084,
      "loss": 0.2054,
      "step": 8100
    },
    {
      "epoch": 1.3867749027566378,
      "grad_norm": 0.3828260004520416,
      "learning_rate": 0.000539544349595794,
      "loss": 0.2108,
      "step": 8200
    },
    {
      "epoch": 1.4036867918146456,
      "grad_norm": 1.2614760398864746,
      "learning_rate": 0.0005338911187743795,
      "loss": 0.2409,
      "step": 8300
    },
    {
      "epoch": 1.4205986808726534,
      "grad_norm": 0.5704723000526428,
      "learning_rate": 0.0005282378879529651,
      "loss": 0.2156,
      "step": 8400
    },
    {
      "epoch": 1.4375105699306612,
      "grad_norm": 0.5831475257873535,
      "learning_rate": 0.0005225846571315507,
      "loss": 0.2084,
      "step": 8500
    },
    {
      "epoch": 1.454422458988669,
      "grad_norm": 0.8558249473571777,
      "learning_rate": 0.0005169314263101363,
      "loss": 0.2144,
      "step": 8600
    },
    {
      "epoch": 1.4713343480466767,
      "grad_norm": 0.7092726826667786,
      "learning_rate": 0.0005112781954887218,
      "loss": 0.2344,
      "step": 8700
    },
    {
      "epoch": 1.4882462371046845,
      "grad_norm": 1.0252639055252075,
      "learning_rate": 0.0005056814969755216,
      "loss": 0.1975,
      "step": 8800
    },
    {
      "epoch": 1.5051581261626925,
      "grad_norm": 0.48172062635421753,
      "learning_rate": 0.0005000282661541071,
      "loss": 0.2155,
      "step": 8900
    },
    {
      "epoch": 1.5220700152207,
      "grad_norm": 0.6334866881370544,
      "learning_rate": 0.0004943750353326926,
      "loss": 0.1964,
      "step": 9000
    },
    {
      "epoch": 1.5220700152207,
      "eval_loss": 0.38619112968444824,
      "eval_runtime": 160.8483,
      "eval_samples_per_second": 125.982,
      "eval_steps_per_second": 15.748,
      "step": 9000
    },
    {
      "epoch": 1.538981904278708,
      "grad_norm": 0.948123037815094,
      "learning_rate": 0.0004887218045112781,
      "loss": 0.2034,
      "step": 9100
    },
    {
      "epoch": 1.5558937933367156,
      "grad_norm": 0.43221917748451233,
      "learning_rate": 0.0004830685736898638,
      "loss": 0.2172,
      "step": 9200
    },
    {
      "epoch": 1.5728056823947236,
      "grad_norm": 0.7101889848709106,
      "learning_rate": 0.00047741534286844937,
      "loss": 0.2045,
      "step": 9300
    },
    {
      "epoch": 1.5897175714527312,
      "grad_norm": 0.877738356590271,
      "learning_rate": 0.00047176211204703487,
      "loss": 0.2251,
      "step": 9400
    },
    {
      "epoch": 1.6066294605107392,
      "grad_norm": 0.5079389810562134,
      "learning_rate": 0.00046610888122562043,
      "loss": 0.213,
      "step": 9500
    },
    {
      "epoch": 1.6235413495687467,
      "grad_norm": 0.6394044756889343,
      "learning_rate": 0.000460455650404206,
      "loss": 0.2203,
      "step": 9600
    },
    {
      "epoch": 1.6404532386267547,
      "grad_norm": 0.12084407359361649,
      "learning_rate": 0.00045480241958279155,
      "loss": 0.1986,
      "step": 9700
    },
    {
      "epoch": 1.6573651276847623,
      "grad_norm": 1.1097984313964844,
      "learning_rate": 0.0004491491887613771,
      "loss": 0.1891,
      "step": 9800
    },
    {
      "epoch": 1.6742770167427703,
      "grad_norm": 0.6052554845809937,
      "learning_rate": 0.00044349595793996273,
      "loss": 0.2218,
      "step": 9900
    },
    {
      "epoch": 1.6911889058007779,
      "grad_norm": 0.677287220954895,
      "learning_rate": 0.0004378427271185483,
      "loss": 0.1977,
      "step": 10000
    },
    {
      "epoch": 1.6911889058007779,
      "eval_loss": 0.37686964869499207,
      "eval_runtime": 162.042,
      "eval_samples_per_second": 125.054,
      "eval_steps_per_second": 15.632,
      "step": 10000
    },
    {
      "epoch": 1.7081007948587859,
      "grad_norm": 0.7823886871337891,
      "learning_rate": 0.00043218949629713385,
      "loss": 0.2144,
      "step": 10100
    },
    {
      "epoch": 1.7250126839167934,
      "grad_norm": 0.568284809589386,
      "learning_rate": 0.0004265362654757194,
      "loss": 0.2119,
      "step": 10200
    },
    {
      "epoch": 1.7419245729748014,
      "grad_norm": 1.3919451236724854,
      "learning_rate": 0.00042088303465430497,
      "loss": 0.198,
      "step": 10300
    },
    {
      "epoch": 1.758836462032809,
      "grad_norm": 0.912038266658783,
      "learning_rate": 0.0004152298038328905,
      "loss": 0.2055,
      "step": 10400
    },
    {
      "epoch": 1.775748351090817,
      "grad_norm": 0.8868546485900879,
      "learning_rate": 0.00040957657301147603,
      "loss": 0.2058,
      "step": 10500
    },
    {
      "epoch": 1.7926602401488245,
      "grad_norm": 0.5976852178573608,
      "learning_rate": 0.0004039233421900616,
      "loss": 0.2223,
      "step": 10600
    },
    {
      "epoch": 1.8095721292068325,
      "grad_norm": 0.7314093112945557,
      "learning_rate": 0.0003982701113686472,
      "loss": 0.1991,
      "step": 10700
    },
    {
      "epoch": 1.82648401826484,
      "grad_norm": 1.0238455533981323,
      "learning_rate": 0.00039261688054723277,
      "loss": 0.191,
      "step": 10800
    },
    {
      "epoch": 1.843395907322848,
      "grad_norm": 1.2027342319488525,
      "learning_rate": 0.00038696364972581833,
      "loss": 0.1973,
      "step": 10900
    },
    {
      "epoch": 1.8603077963808556,
      "grad_norm": 0.5567656755447388,
      "learning_rate": 0.000381366951212618,
      "loss": 0.2192,
      "step": 11000
    },
    {
      "epoch": 1.8603077963808556,
      "eval_loss": 0.37566691637039185,
      "eval_runtime": 160.7768,
      "eval_samples_per_second": 126.038,
      "eval_steps_per_second": 15.755,
      "step": 11000
    },
    {
      "epoch": 1.8772196854388636,
      "grad_norm": 0.33648815751075745,
      "learning_rate": 0.0003757137203912036,
      "loss": 0.1972,
      "step": 11100
    },
    {
      "epoch": 1.8941315744968712,
      "grad_norm": 0.4922679364681244,
      "learning_rate": 0.0003700604895697892,
      "loss": 0.2083,
      "step": 11200
    },
    {
      "epoch": 1.9110434635548792,
      "grad_norm": 0.8587576150894165,
      "learning_rate": 0.0003644072587483747,
      "loss": 0.1999,
      "step": 11300
    },
    {
      "epoch": 1.9279553526128868,
      "grad_norm": 1.1008392572402954,
      "learning_rate": 0.00035875402792696025,
      "loss": 0.1865,
      "step": 11400
    },
    {
      "epoch": 1.9448672416708948,
      "grad_norm": 1.1125046014785767,
      "learning_rate": 0.0003531007971055458,
      "loss": 0.1862,
      "step": 11500
    },
    {
      "epoch": 1.9617791307289023,
      "grad_norm": 0.9952799081802368,
      "learning_rate": 0.00034744756628413137,
      "loss": 0.1912,
      "step": 11600
    },
    {
      "epoch": 1.9786910197869103,
      "grad_norm": 0.34466665983200073,
      "learning_rate": 0.00034179433546271693,
      "loss": 0.1725,
      "step": 11700
    },
    {
      "epoch": 1.9956029088449179,
      "grad_norm": 1.6026116609573364,
      "learning_rate": 0.0003361411046413025,
      "loss": 0.2083,
      "step": 11800
    },
    {
      "epoch": 2.012514797902926,
      "grad_norm": 0.9120477437973022,
      "learning_rate": 0.0003304878738198881,
      "loss": 0.1513,
      "step": 11900
    },
    {
      "epoch": 2.0294266869609334,
      "grad_norm": 0.7204672694206238,
      "learning_rate": 0.00032483464299847367,
      "loss": 0.1363,
      "step": 12000
    },
    {
      "epoch": 2.0294266869609334,
      "eval_loss": 0.3693881332874298,
      "eval_runtime": 161.2417,
      "eval_samples_per_second": 125.675,
      "eval_steps_per_second": 15.709,
      "step": 12000
    }
  ],
  "logging_steps": 100,
  "max_steps": 17739,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.45042206674944e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

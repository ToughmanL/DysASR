{
  "best_metric": 0.11117493361234665,
  "best_model_checkpoint": "output/MSDM/whisper-base/checkpoint-6000",
  "epoch": 2.067539627842867,
  "eval_steps": 1000,
  "global_step": 9000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02297266253158741,
      "grad_norm": 1.064448595046997,
      "learning_rate": 0.0009963871166115766,
      "loss": 1.8894,
      "step": 100
    },
    {
      "epoch": 0.04594532506317482,
      "grad_norm": 0.903581976890564,
      "learning_rate": 0.000988700130678761,
      "loss": 0.4617,
      "step": 200
    },
    {
      "epoch": 0.06891798759476224,
      "grad_norm": 1.031436562538147,
      "learning_rate": 0.0009810131447459452,
      "loss": 0.3338,
      "step": 300
    },
    {
      "epoch": 0.09189065012634964,
      "grad_norm": 0.6364169716835022,
      "learning_rate": 0.0009733261588131294,
      "loss": 0.2922,
      "step": 400
    },
    {
      "epoch": 0.11486331265793706,
      "grad_norm": 1.2408772706985474,
      "learning_rate": 0.0009656391728803137,
      "loss": 0.2565,
      "step": 500
    },
    {
      "epoch": 0.13783597518952448,
      "grad_norm": 0.8569642901420593,
      "learning_rate": 0.0009579521869474978,
      "loss": 0.2512,
      "step": 600
    },
    {
      "epoch": 0.16080863772111187,
      "grad_norm": 1.1169185638427734,
      "learning_rate": 0.0009502652010146822,
      "loss": 0.2067,
      "step": 700
    },
    {
      "epoch": 0.1837813002526993,
      "grad_norm": 1.0236374139785767,
      "learning_rate": 0.0009425782150818665,
      "loss": 0.1936,
      "step": 800
    },
    {
      "epoch": 0.2067539627842867,
      "grad_norm": 1.2776081562042236,
      "learning_rate": 0.0009348912291490506,
      "loss": 0.178,
      "step": 900
    },
    {
      "epoch": 0.22972662531587412,
      "grad_norm": 0.100974902510643,
      "learning_rate": 0.000927204243216235,
      "loss": 0.1569,
      "step": 1000
    },
    {
      "epoch": 0.22972662531587412,
      "eval_loss": 0.1728297621011734,
      "eval_runtime": 60.8954,
      "eval_samples_per_second": 116.15,
      "eval_steps_per_second": 14.533,
      "step": 1000
    },
    {
      "epoch": 0.25269928784746154,
      "grad_norm": 0.748829185962677,
      "learning_rate": 0.0009195172572834192,
      "loss": 0.1678,
      "step": 1100
    },
    {
      "epoch": 0.27567195037904896,
      "grad_norm": 0.8101602792739868,
      "learning_rate": 0.0009119071412099315,
      "loss": 0.1691,
      "step": 1200
    },
    {
      "epoch": 0.2986446129106363,
      "grad_norm": 0.0675700306892395,
      "learning_rate": 0.0009042201552771159,
      "loss": 0.1678,
      "step": 1300
    },
    {
      "epoch": 0.32161727544222374,
      "grad_norm": 0.8379897475242615,
      "learning_rate": 0.0008965331693443001,
      "loss": 0.118,
      "step": 1400
    },
    {
      "epoch": 0.34458993797381116,
      "grad_norm": 0.5222977995872498,
      "learning_rate": 0.0008888461834114843,
      "loss": 0.1528,
      "step": 1500
    },
    {
      "epoch": 0.3675626005053986,
      "grad_norm": 2.655409336090088,
      "learning_rate": 0.0008811591974786687,
      "loss": 0.1439,
      "step": 1600
    },
    {
      "epoch": 0.390535263036986,
      "grad_norm": 0.6513972282409668,
      "learning_rate": 0.0008734722115458529,
      "loss": 0.1478,
      "step": 1700
    },
    {
      "epoch": 0.4135079255685734,
      "grad_norm": 0.7068172097206116,
      "learning_rate": 0.0008657852256130371,
      "loss": 0.1592,
      "step": 1800
    },
    {
      "epoch": 0.4364805881001608,
      "grad_norm": 0.5109686851501465,
      "learning_rate": 0.0008580982396802214,
      "loss": 0.1305,
      "step": 1900
    },
    {
      "epoch": 0.45945325063174824,
      "grad_norm": 0.15401135385036469,
      "learning_rate": 0.0008504112537474057,
      "loss": 0.1336,
      "step": 2000
    },
    {
      "epoch": 0.45945325063174824,
      "eval_loss": 0.13719777762889862,
      "eval_runtime": 60.2261,
      "eval_samples_per_second": 117.441,
      "eval_steps_per_second": 14.695,
      "step": 2000
    },
    {
      "epoch": 0.4824259131633356,
      "grad_norm": 0.5687255263328552,
      "learning_rate": 0.0008427242678145898,
      "loss": 0.1299,
      "step": 2100
    },
    {
      "epoch": 0.5053985756949231,
      "grad_norm": 0.7918844223022461,
      "learning_rate": 0.0008350372818817742,
      "loss": 0.1118,
      "step": 2200
    },
    {
      "epoch": 0.5283712382265104,
      "grad_norm": 0.48733389377593994,
      "learning_rate": 0.0008273502959489584,
      "loss": 0.1238,
      "step": 2300
    },
    {
      "epoch": 0.5513439007580979,
      "grad_norm": 0.6068286299705505,
      "learning_rate": 0.0008196633100161427,
      "loss": 0.1192,
      "step": 2400
    },
    {
      "epoch": 0.5743165632896853,
      "grad_norm": 0.8527357578277588,
      "learning_rate": 0.0008119763240833269,
      "loss": 0.1284,
      "step": 2500
    },
    {
      "epoch": 0.5972892258212726,
      "grad_norm": 0.7333431243896484,
      "learning_rate": 0.0008042893381505112,
      "loss": 0.1142,
      "step": 2600
    },
    {
      "epoch": 0.6202618883528601,
      "grad_norm": 0.960456371307373,
      "learning_rate": 0.0007966023522176955,
      "loss": 0.1116,
      "step": 2700
    },
    {
      "epoch": 0.6432345508844475,
      "grad_norm": 1.341153860092163,
      "learning_rate": 0.0007889153662848797,
      "loss": 0.1037,
      "step": 2800
    },
    {
      "epoch": 0.666207213416035,
      "grad_norm": 0.16356603801250458,
      "learning_rate": 0.000781228380352064,
      "loss": 0.1192,
      "step": 2900
    },
    {
      "epoch": 0.6891798759476223,
      "grad_norm": 0.455654501914978,
      "learning_rate": 0.0007735413944192482,
      "loss": 0.1127,
      "step": 3000
    },
    {
      "epoch": 0.6891798759476223,
      "eval_loss": 0.11863977462053299,
      "eval_runtime": 60.3532,
      "eval_samples_per_second": 117.193,
      "eval_steps_per_second": 14.664,
      "step": 3000
    },
    {
      "epoch": 0.7121525384792098,
      "grad_norm": 0.6002146601676941,
      "learning_rate": 0.0007658544084864325,
      "loss": 0.111,
      "step": 3100
    },
    {
      "epoch": 0.7351252010107971,
      "grad_norm": 1.282518982887268,
      "learning_rate": 0.0007581674225536167,
      "loss": 0.1088,
      "step": 3200
    },
    {
      "epoch": 0.7580978635423845,
      "grad_norm": 0.7249883413314819,
      "learning_rate": 0.000750480436620801,
      "loss": 0.1134,
      "step": 3300
    },
    {
      "epoch": 0.781070526073972,
      "grad_norm": 0.4195556044578552,
      "learning_rate": 0.0007427934506879853,
      "loss": 0.0933,
      "step": 3400
    },
    {
      "epoch": 0.8040431886055593,
      "grad_norm": 1.5229700803756714,
      "learning_rate": 0.0007351064647551695,
      "loss": 0.0991,
      "step": 3500
    },
    {
      "epoch": 0.8270158511371468,
      "grad_norm": 0.8772228956222534,
      "learning_rate": 0.0007274194788223538,
      "loss": 0.0963,
      "step": 3600
    },
    {
      "epoch": 0.8499885136687342,
      "grad_norm": 0.49114474654197693,
      "learning_rate": 0.000719732492889538,
      "loss": 0.0809,
      "step": 3700
    },
    {
      "epoch": 0.8729611762003217,
      "grad_norm": 0.1075345128774643,
      "learning_rate": 0.0007120455069567223,
      "loss": 0.1037,
      "step": 3800
    },
    {
      "epoch": 0.895933838731909,
      "grad_norm": 0.49395638704299927,
      "learning_rate": 0.0007043585210239065,
      "loss": 0.1,
      "step": 3900
    },
    {
      "epoch": 0.9189065012634965,
      "grad_norm": 1.4807441234588623,
      "learning_rate": 0.0006966715350910908,
      "loss": 0.094,
      "step": 4000
    },
    {
      "epoch": 0.9189065012634965,
      "eval_loss": 0.11404117196798325,
      "eval_runtime": 60.4419,
      "eval_samples_per_second": 117.022,
      "eval_steps_per_second": 14.642,
      "step": 4000
    },
    {
      "epoch": 0.9418791637950839,
      "grad_norm": 0.3657117486000061,
      "learning_rate": 0.000688984549158275,
      "loss": 0.0843,
      "step": 4100
    },
    {
      "epoch": 0.9648518263266712,
      "grad_norm": 0.41236716508865356,
      "learning_rate": 0.0006812975632254593,
      "loss": 0.1023,
      "step": 4200
    },
    {
      "epoch": 0.9878244888582587,
      "grad_norm": 0.5247601270675659,
      "learning_rate": 0.0006736105772926435,
      "loss": 0.1101,
      "step": 4300
    },
    {
      "epoch": 1.0107971513898462,
      "grad_norm": 0.14091354608535767,
      "learning_rate": 0.0006659235913598279,
      "loss": 0.0741,
      "step": 4400
    },
    {
      "epoch": 1.0337698139214335,
      "grad_norm": 0.44335493445396423,
      "learning_rate": 0.0006582366054270121,
      "loss": 0.0757,
      "step": 4500
    },
    {
      "epoch": 1.0567424764530209,
      "grad_norm": 0.7220605611801147,
      "learning_rate": 0.0006505496194941963,
      "loss": 0.0685,
      "step": 4600
    },
    {
      "epoch": 1.0797151389846082,
      "grad_norm": 0.9507549405097961,
      "learning_rate": 0.0006428626335613807,
      "loss": 0.0678,
      "step": 4700
    },
    {
      "epoch": 1.1026878015161956,
      "grad_norm": 0.6687594652175903,
      "learning_rate": 0.0006351756476285648,
      "loss": 0.0651,
      "step": 4800
    },
    {
      "epoch": 1.1256604640477832,
      "grad_norm": 0.5456072688102722,
      "learning_rate": 0.0006274886616957491,
      "loss": 0.0623,
      "step": 4900
    },
    {
      "epoch": 1.1486331265793706,
      "grad_norm": 1.9329068660736084,
      "learning_rate": 0.0006198016757629334,
      "loss": 0.0609,
      "step": 5000
    },
    {
      "epoch": 1.1486331265793706,
      "eval_loss": 0.11948409676551819,
      "eval_runtime": 59.0424,
      "eval_samples_per_second": 119.795,
      "eval_steps_per_second": 14.989,
      "step": 5000
    },
    {
      "epoch": 1.171605789110958,
      "grad_norm": 0.3321975767612457,
      "learning_rate": 0.0006121146898301176,
      "loss": 0.0603,
      "step": 5100
    },
    {
      "epoch": 1.1945784516425453,
      "grad_norm": 0.2880999445915222,
      "learning_rate": 0.0006044277038973018,
      "loss": 0.0617,
      "step": 5200
    },
    {
      "epoch": 1.2175511141741329,
      "grad_norm": 0.6116036772727966,
      "learning_rate": 0.0005967407179644862,
      "loss": 0.0604,
      "step": 5300
    },
    {
      "epoch": 1.2405237767057202,
      "grad_norm": 0.7618772983551025,
      "learning_rate": 0.0005890537320316704,
      "loss": 0.0702,
      "step": 5400
    },
    {
      "epoch": 1.2634964392373076,
      "grad_norm": 0.8238525390625,
      "learning_rate": 0.0005813667460988546,
      "loss": 0.063,
      "step": 5500
    },
    {
      "epoch": 1.286469101768895,
      "grad_norm": 0.10191330313682556,
      "learning_rate": 0.000573679760166039,
      "loss": 0.0646,
      "step": 5600
    },
    {
      "epoch": 1.3094417643004825,
      "grad_norm": 0.4983886182308197,
      "learning_rate": 0.0005659927742332232,
      "loss": 0.06,
      "step": 5700
    },
    {
      "epoch": 1.33241442683207,
      "grad_norm": 0.33263933658599854,
      "learning_rate": 0.0005583057883004074,
      "loss": 0.0538,
      "step": 5800
    },
    {
      "epoch": 1.3553870893636573,
      "grad_norm": 0.1824229210615158,
      "learning_rate": 0.0005506188023675916,
      "loss": 0.0785,
      "step": 5900
    },
    {
      "epoch": 1.3783597518952446,
      "grad_norm": 0.8580570220947266,
      "learning_rate": 0.000542931816434776,
      "loss": 0.0558,
      "step": 6000
    },
    {
      "epoch": 1.3783597518952446,
      "eval_loss": 0.11117493361234665,
      "eval_runtime": 59.5802,
      "eval_samples_per_second": 118.714,
      "eval_steps_per_second": 14.854,
      "step": 6000
    },
    {
      "epoch": 1.401332414426832,
      "grad_norm": 0.25424349308013916,
      "learning_rate": 0.0005353217003612883,
      "loss": 0.0652,
      "step": 6100
    },
    {
      "epoch": 1.4243050769584196,
      "grad_norm": 1.342605710029602,
      "learning_rate": 0.0005276347144284727,
      "loss": 0.0613,
      "step": 6200
    },
    {
      "epoch": 1.447277739490007,
      "grad_norm": 0.21206073462963104,
      "learning_rate": 0.0005199477284956569,
      "loss": 0.0545,
      "step": 6300
    },
    {
      "epoch": 1.4702504020215943,
      "grad_norm": 0.936102032661438,
      "learning_rate": 0.0005122607425628411,
      "loss": 0.0624,
      "step": 6400
    },
    {
      "epoch": 1.4932230645531817,
      "grad_norm": 0.9632294178009033,
      "learning_rate": 0.0005045737566300254,
      "loss": 0.0534,
      "step": 6500
    },
    {
      "epoch": 1.516195727084769,
      "grad_norm": 1.6170355081558228,
      "learning_rate": 0.0004968867706972096,
      "loss": 0.0658,
      "step": 6600
    },
    {
      "epoch": 1.5391683896163566,
      "grad_norm": 0.8836139440536499,
      "learning_rate": 0.0004891997847643939,
      "loss": 0.0511,
      "step": 6700
    },
    {
      "epoch": 1.562141052147944,
      "grad_norm": 0.015006158500909805,
      "learning_rate": 0.00048151279883157816,
      "loss": 0.0627,
      "step": 6800
    },
    {
      "epoch": 1.5851137146795313,
      "grad_norm": 0.2702689468860626,
      "learning_rate": 0.00047382581289876245,
      "loss": 0.069,
      "step": 6900
    },
    {
      "epoch": 1.608086377211119,
      "grad_norm": 0.5842597484588623,
      "learning_rate": 0.0004661388269659467,
      "loss": 0.0763,
      "step": 7000
    },
    {
      "epoch": 1.608086377211119,
      "eval_loss": 0.11360197514295578,
      "eval_runtime": 60.6041,
      "eval_samples_per_second": 116.708,
      "eval_steps_per_second": 14.603,
      "step": 7000
    },
    {
      "epoch": 1.631059039742706,
      "grad_norm": 0.5837859511375427,
      "learning_rate": 0.0004584518410331309,
      "loss": 0.067,
      "step": 7100
    },
    {
      "epoch": 1.6540317022742936,
      "grad_norm": 0.5414097309112549,
      "learning_rate": 0.0004507648551003152,
      "loss": 0.0705,
      "step": 7200
    },
    {
      "epoch": 1.677004364805881,
      "grad_norm": 0.8300212025642395,
      "learning_rate": 0.0004430778691674994,
      "loss": 0.0601,
      "step": 7300
    },
    {
      "epoch": 1.6999770273374684,
      "grad_norm": 0.7662331461906433,
      "learning_rate": 0.00043539088323468365,
      "loss": 0.0613,
      "step": 7400
    },
    {
      "epoch": 1.722949689869056,
      "grad_norm": 0.9201924204826355,
      "learning_rate": 0.00042770389730186793,
      "loss": 0.0649,
      "step": 7500
    },
    {
      "epoch": 1.745922352400643,
      "grad_norm": 0.197792187333107,
      "learning_rate": 0.00042001691136905216,
      "loss": 0.0601,
      "step": 7600
    },
    {
      "epoch": 1.7688950149322307,
      "grad_norm": 0.7463710308074951,
      "learning_rate": 0.0004123299254362365,
      "loss": 0.0563,
      "step": 7700
    },
    {
      "epoch": 1.791867677463818,
      "grad_norm": 0.743771493434906,
      "learning_rate": 0.00040464293950342073,
      "loss": 0.0592,
      "step": 7800
    },
    {
      "epoch": 1.8148403399954054,
      "grad_norm": 1.6979279518127441,
      "learning_rate": 0.00039695595357060496,
      "loss": 0.0624,
      "step": 7900
    },
    {
      "epoch": 1.837813002526993,
      "grad_norm": 1.383826732635498,
      "learning_rate": 0.00038926896763778925,
      "loss": 0.0578,
      "step": 8000
    },
    {
      "epoch": 1.837813002526993,
      "eval_loss": 0.11247429251670837,
      "eval_runtime": 61.3109,
      "eval_samples_per_second": 115.363,
      "eval_steps_per_second": 14.435,
      "step": 8000
    },
    {
      "epoch": 1.8607856650585803,
      "grad_norm": 0.18213355541229248,
      "learning_rate": 0.0003815819817049735,
      "loss": 0.0595,
      "step": 8100
    },
    {
      "epoch": 1.8837583275901677,
      "grad_norm": 0.4890602231025696,
      "learning_rate": 0.00037389499577215776,
      "loss": 0.0586,
      "step": 8200
    },
    {
      "epoch": 1.906730990121755,
      "grad_norm": 0.2965359389781952,
      "learning_rate": 0.000366208009839342,
      "loss": 0.0494,
      "step": 8300
    },
    {
      "epoch": 1.9297036526533424,
      "grad_norm": 0.3813123404979706,
      "learning_rate": 0.0003585210239065262,
      "loss": 0.0549,
      "step": 8400
    },
    {
      "epoch": 1.95267631518493,
      "grad_norm": 0.08090025186538696,
      "learning_rate": 0.0003508340379737105,
      "loss": 0.0505,
      "step": 8500
    },
    {
      "epoch": 1.9756489777165174,
      "grad_norm": 0.9823183417320251,
      "learning_rate": 0.00034314705204089473,
      "loss": 0.0576,
      "step": 8600
    },
    {
      "epoch": 1.9986216402481047,
      "grad_norm": 0.07828344404697418,
      "learning_rate": 0.00033546006610807907,
      "loss": 0.0513,
      "step": 8700
    },
    {
      "epoch": 2.0215943027796923,
      "grad_norm": 0.5994260907173157,
      "learning_rate": 0.0003277730801752633,
      "loss": 0.0299,
      "step": 8800
    },
    {
      "epoch": 2.0445669653112795,
      "grad_norm": 1.1318439245224,
      "learning_rate": 0.0003201629641017757,
      "loss": 0.0337,
      "step": 8900
    },
    {
      "epoch": 2.067539627842867,
      "grad_norm": 0.18401454389095306,
      "learning_rate": 0.00031247597816895994,
      "loss": 0.0403,
      "step": 9000
    },
    {
      "epoch": 2.067539627842867,
      "eval_loss": 0.11242201924324036,
      "eval_runtime": 60.7592,
      "eval_samples_per_second": 116.41,
      "eval_steps_per_second": 14.566,
      "step": 9000
    }
  ],
  "logging_steps": 100,
  "max_steps": 13059,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.83795094505472e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

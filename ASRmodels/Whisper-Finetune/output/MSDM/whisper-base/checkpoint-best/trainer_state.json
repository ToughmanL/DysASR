{
  "best_metric": 0.10991289466619492,
  "best_model_checkpoint": "output/MSDM/whisper-base/checkpoint-13000",
  "epoch": 2.9864461291063633,
  "eval_steps": 1000,
  "global_step": 13000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02297266253158741,
      "grad_norm": 1.064448595046997,
      "learning_rate": 0.0009963871166115766,
      "loss": 1.8894,
      "step": 100
    },
    {
      "epoch": 0.04594532506317482,
      "grad_norm": 0.903581976890564,
      "learning_rate": 0.000988700130678761,
      "loss": 0.4617,
      "step": 200
    },
    {
      "epoch": 0.06891798759476224,
      "grad_norm": 1.031436562538147,
      "learning_rate": 0.0009810131447459452,
      "loss": 0.3338,
      "step": 300
    },
    {
      "epoch": 0.09189065012634964,
      "grad_norm": 0.6364169716835022,
      "learning_rate": 0.0009733261588131294,
      "loss": 0.2922,
      "step": 400
    },
    {
      "epoch": 0.11486331265793706,
      "grad_norm": 1.2408772706985474,
      "learning_rate": 0.0009656391728803137,
      "loss": 0.2565,
      "step": 500
    },
    {
      "epoch": 0.13783597518952448,
      "grad_norm": 0.8569642901420593,
      "learning_rate": 0.0009579521869474978,
      "loss": 0.2512,
      "step": 600
    },
    {
      "epoch": 0.16080863772111187,
      "grad_norm": 1.1169185638427734,
      "learning_rate": 0.0009502652010146822,
      "loss": 0.2067,
      "step": 700
    },
    {
      "epoch": 0.1837813002526993,
      "grad_norm": 1.0236374139785767,
      "learning_rate": 0.0009425782150818665,
      "loss": 0.1936,
      "step": 800
    },
    {
      "epoch": 0.2067539627842867,
      "grad_norm": 1.2776081562042236,
      "learning_rate": 0.0009348912291490506,
      "loss": 0.178,
      "step": 900
    },
    {
      "epoch": 0.22972662531587412,
      "grad_norm": 0.100974902510643,
      "learning_rate": 0.000927204243216235,
      "loss": 0.1569,
      "step": 1000
    },
    {
      "epoch": 0.22972662531587412,
      "eval_loss": 0.1728297621011734,
      "eval_runtime": 60.8954,
      "eval_samples_per_second": 116.15,
      "eval_steps_per_second": 14.533,
      "step": 1000
    },
    {
      "epoch": 0.25269928784746154,
      "grad_norm": 0.748829185962677,
      "learning_rate": 0.0009195172572834192,
      "loss": 0.1678,
      "step": 1100
    },
    {
      "epoch": 0.27567195037904896,
      "grad_norm": 0.8101602792739868,
      "learning_rate": 0.0009119071412099315,
      "loss": 0.1691,
      "step": 1200
    },
    {
      "epoch": 0.2986446129106363,
      "grad_norm": 0.0675700306892395,
      "learning_rate": 0.0009042201552771159,
      "loss": 0.1678,
      "step": 1300
    },
    {
      "epoch": 0.32161727544222374,
      "grad_norm": 0.8379897475242615,
      "learning_rate": 0.0008965331693443001,
      "loss": 0.118,
      "step": 1400
    },
    {
      "epoch": 0.34458993797381116,
      "grad_norm": 0.5222977995872498,
      "learning_rate": 0.0008888461834114843,
      "loss": 0.1528,
      "step": 1500
    },
    {
      "epoch": 0.3675626005053986,
      "grad_norm": 2.655409336090088,
      "learning_rate": 0.0008811591974786687,
      "loss": 0.1439,
      "step": 1600
    },
    {
      "epoch": 0.390535263036986,
      "grad_norm": 0.6513972282409668,
      "learning_rate": 0.0008734722115458529,
      "loss": 0.1478,
      "step": 1700
    },
    {
      "epoch": 0.4135079255685734,
      "grad_norm": 0.7068172097206116,
      "learning_rate": 0.0008657852256130371,
      "loss": 0.1592,
      "step": 1800
    },
    {
      "epoch": 0.4364805881001608,
      "grad_norm": 0.5109686851501465,
      "learning_rate": 0.0008580982396802214,
      "loss": 0.1305,
      "step": 1900
    },
    {
      "epoch": 0.45945325063174824,
      "grad_norm": 0.15401135385036469,
      "learning_rate": 0.0008504112537474057,
      "loss": 0.1336,
      "step": 2000
    },
    {
      "epoch": 0.45945325063174824,
      "eval_loss": 0.13719777762889862,
      "eval_runtime": 60.2261,
      "eval_samples_per_second": 117.441,
      "eval_steps_per_second": 14.695,
      "step": 2000
    },
    {
      "epoch": 0.4824259131633356,
      "grad_norm": 0.5687255263328552,
      "learning_rate": 0.0008427242678145898,
      "loss": 0.1299,
      "step": 2100
    },
    {
      "epoch": 0.5053985756949231,
      "grad_norm": 0.7918844223022461,
      "learning_rate": 0.0008350372818817742,
      "loss": 0.1118,
      "step": 2200
    },
    {
      "epoch": 0.5283712382265104,
      "grad_norm": 0.48733389377593994,
      "learning_rate": 0.0008273502959489584,
      "loss": 0.1238,
      "step": 2300
    },
    {
      "epoch": 0.5513439007580979,
      "grad_norm": 0.6068286299705505,
      "learning_rate": 0.0008196633100161427,
      "loss": 0.1192,
      "step": 2400
    },
    {
      "epoch": 0.5743165632896853,
      "grad_norm": 0.8527357578277588,
      "learning_rate": 0.0008119763240833269,
      "loss": 0.1284,
      "step": 2500
    },
    {
      "epoch": 0.5972892258212726,
      "grad_norm": 0.7333431243896484,
      "learning_rate": 0.0008042893381505112,
      "loss": 0.1142,
      "step": 2600
    },
    {
      "epoch": 0.6202618883528601,
      "grad_norm": 0.960456371307373,
      "learning_rate": 0.0007966023522176955,
      "loss": 0.1116,
      "step": 2700
    },
    {
      "epoch": 0.6432345508844475,
      "grad_norm": 1.341153860092163,
      "learning_rate": 0.0007889153662848797,
      "loss": 0.1037,
      "step": 2800
    },
    {
      "epoch": 0.666207213416035,
      "grad_norm": 0.16356603801250458,
      "learning_rate": 0.000781228380352064,
      "loss": 0.1192,
      "step": 2900
    },
    {
      "epoch": 0.6891798759476223,
      "grad_norm": 0.455654501914978,
      "learning_rate": 0.0007735413944192482,
      "loss": 0.1127,
      "step": 3000
    },
    {
      "epoch": 0.6891798759476223,
      "eval_loss": 0.11863977462053299,
      "eval_runtime": 60.3532,
      "eval_samples_per_second": 117.193,
      "eval_steps_per_second": 14.664,
      "step": 3000
    },
    {
      "epoch": 0.7121525384792098,
      "grad_norm": 0.6002146601676941,
      "learning_rate": 0.0007658544084864325,
      "loss": 0.111,
      "step": 3100
    },
    {
      "epoch": 0.7351252010107971,
      "grad_norm": 1.282518982887268,
      "learning_rate": 0.0007581674225536167,
      "loss": 0.1088,
      "step": 3200
    },
    {
      "epoch": 0.7580978635423845,
      "grad_norm": 0.7249883413314819,
      "learning_rate": 0.000750480436620801,
      "loss": 0.1134,
      "step": 3300
    },
    {
      "epoch": 0.781070526073972,
      "grad_norm": 0.4195556044578552,
      "learning_rate": 0.0007427934506879853,
      "loss": 0.0933,
      "step": 3400
    },
    {
      "epoch": 0.8040431886055593,
      "grad_norm": 1.5229700803756714,
      "learning_rate": 0.0007351064647551695,
      "loss": 0.0991,
      "step": 3500
    },
    {
      "epoch": 0.8270158511371468,
      "grad_norm": 0.8772228956222534,
      "learning_rate": 0.0007274194788223538,
      "loss": 0.0963,
      "step": 3600
    },
    {
      "epoch": 0.8499885136687342,
      "grad_norm": 0.49114474654197693,
      "learning_rate": 0.000719732492889538,
      "loss": 0.0809,
      "step": 3700
    },
    {
      "epoch": 0.8729611762003217,
      "grad_norm": 0.1075345128774643,
      "learning_rate": 0.0007120455069567223,
      "loss": 0.1037,
      "step": 3800
    },
    {
      "epoch": 0.895933838731909,
      "grad_norm": 0.49395638704299927,
      "learning_rate": 0.0007043585210239065,
      "loss": 0.1,
      "step": 3900
    },
    {
      "epoch": 0.9189065012634965,
      "grad_norm": 1.4807441234588623,
      "learning_rate": 0.0006966715350910908,
      "loss": 0.094,
      "step": 4000
    },
    {
      "epoch": 0.9189065012634965,
      "eval_loss": 0.11404117196798325,
      "eval_runtime": 60.4419,
      "eval_samples_per_second": 117.022,
      "eval_steps_per_second": 14.642,
      "step": 4000
    },
    {
      "epoch": 0.9418791637950839,
      "grad_norm": 0.3657117486000061,
      "learning_rate": 0.000688984549158275,
      "loss": 0.0843,
      "step": 4100
    },
    {
      "epoch": 0.9648518263266712,
      "grad_norm": 0.41236716508865356,
      "learning_rate": 0.0006812975632254593,
      "loss": 0.1023,
      "step": 4200
    },
    {
      "epoch": 0.9878244888582587,
      "grad_norm": 0.5247601270675659,
      "learning_rate": 0.0006736105772926435,
      "loss": 0.1101,
      "step": 4300
    },
    {
      "epoch": 1.0107971513898462,
      "grad_norm": 0.14091354608535767,
      "learning_rate": 0.0006659235913598279,
      "loss": 0.0741,
      "step": 4400
    },
    {
      "epoch": 1.0337698139214335,
      "grad_norm": 0.44335493445396423,
      "learning_rate": 0.0006582366054270121,
      "loss": 0.0757,
      "step": 4500
    },
    {
      "epoch": 1.0567424764530209,
      "grad_norm": 0.7220605611801147,
      "learning_rate": 0.0006505496194941963,
      "loss": 0.0685,
      "step": 4600
    },
    {
      "epoch": 1.0797151389846082,
      "grad_norm": 0.9507549405097961,
      "learning_rate": 0.0006428626335613807,
      "loss": 0.0678,
      "step": 4700
    },
    {
      "epoch": 1.1026878015161956,
      "grad_norm": 0.6687594652175903,
      "learning_rate": 0.0006351756476285648,
      "loss": 0.0651,
      "step": 4800
    },
    {
      "epoch": 1.1256604640477832,
      "grad_norm": 0.5456072688102722,
      "learning_rate": 0.0006274886616957491,
      "loss": 0.0623,
      "step": 4900
    },
    {
      "epoch": 1.1486331265793706,
      "grad_norm": 1.9329068660736084,
      "learning_rate": 0.0006198016757629334,
      "loss": 0.0609,
      "step": 5000
    },
    {
      "epoch": 1.1486331265793706,
      "eval_loss": 0.11948409676551819,
      "eval_runtime": 59.0424,
      "eval_samples_per_second": 119.795,
      "eval_steps_per_second": 14.989,
      "step": 5000
    },
    {
      "epoch": 1.171605789110958,
      "grad_norm": 0.3321975767612457,
      "learning_rate": 0.0006121146898301176,
      "loss": 0.0603,
      "step": 5100
    },
    {
      "epoch": 1.1945784516425453,
      "grad_norm": 0.2880999445915222,
      "learning_rate": 0.0006044277038973018,
      "loss": 0.0617,
      "step": 5200
    },
    {
      "epoch": 1.2175511141741329,
      "grad_norm": 0.6116036772727966,
      "learning_rate": 0.0005967407179644862,
      "loss": 0.0604,
      "step": 5300
    },
    {
      "epoch": 1.2405237767057202,
      "grad_norm": 0.7618772983551025,
      "learning_rate": 0.0005890537320316704,
      "loss": 0.0702,
      "step": 5400
    },
    {
      "epoch": 1.2634964392373076,
      "grad_norm": 0.8238525390625,
      "learning_rate": 0.0005813667460988546,
      "loss": 0.063,
      "step": 5500
    },
    {
      "epoch": 1.286469101768895,
      "grad_norm": 0.10191330313682556,
      "learning_rate": 0.000573679760166039,
      "loss": 0.0646,
      "step": 5600
    },
    {
      "epoch": 1.3094417643004825,
      "grad_norm": 0.4983886182308197,
      "learning_rate": 0.0005659927742332232,
      "loss": 0.06,
      "step": 5700
    },
    {
      "epoch": 1.33241442683207,
      "grad_norm": 0.33263933658599854,
      "learning_rate": 0.0005583057883004074,
      "loss": 0.0538,
      "step": 5800
    },
    {
      "epoch": 1.3553870893636573,
      "grad_norm": 0.1824229210615158,
      "learning_rate": 0.0005506188023675916,
      "loss": 0.0785,
      "step": 5900
    },
    {
      "epoch": 1.3783597518952446,
      "grad_norm": 0.8580570220947266,
      "learning_rate": 0.000542931816434776,
      "loss": 0.0558,
      "step": 6000
    },
    {
      "epoch": 1.3783597518952446,
      "eval_loss": 0.11117493361234665,
      "eval_runtime": 59.5802,
      "eval_samples_per_second": 118.714,
      "eval_steps_per_second": 14.854,
      "step": 6000
    },
    {
      "epoch": 1.401332414426832,
      "grad_norm": 0.25424349308013916,
      "learning_rate": 0.0005353217003612883,
      "loss": 0.0652,
      "step": 6100
    },
    {
      "epoch": 1.4243050769584196,
      "grad_norm": 1.342605710029602,
      "learning_rate": 0.0005276347144284727,
      "loss": 0.0613,
      "step": 6200
    },
    {
      "epoch": 1.447277739490007,
      "grad_norm": 0.21206073462963104,
      "learning_rate": 0.0005199477284956569,
      "loss": 0.0545,
      "step": 6300
    },
    {
      "epoch": 1.4702504020215943,
      "grad_norm": 0.936102032661438,
      "learning_rate": 0.0005122607425628411,
      "loss": 0.0624,
      "step": 6400
    },
    {
      "epoch": 1.4932230645531817,
      "grad_norm": 0.9632294178009033,
      "learning_rate": 0.0005045737566300254,
      "loss": 0.0534,
      "step": 6500
    },
    {
      "epoch": 1.516195727084769,
      "grad_norm": 1.6170355081558228,
      "learning_rate": 0.0004968867706972096,
      "loss": 0.0658,
      "step": 6600
    },
    {
      "epoch": 1.5391683896163566,
      "grad_norm": 0.8836139440536499,
      "learning_rate": 0.0004891997847643939,
      "loss": 0.0511,
      "step": 6700
    },
    {
      "epoch": 1.562141052147944,
      "grad_norm": 0.015006158500909805,
      "learning_rate": 0.00048151279883157816,
      "loss": 0.0627,
      "step": 6800
    },
    {
      "epoch": 1.5851137146795313,
      "grad_norm": 0.2702689468860626,
      "learning_rate": 0.00047382581289876245,
      "loss": 0.069,
      "step": 6900
    },
    {
      "epoch": 1.608086377211119,
      "grad_norm": 0.5842597484588623,
      "learning_rate": 0.0004661388269659467,
      "loss": 0.0763,
      "step": 7000
    },
    {
      "epoch": 1.608086377211119,
      "eval_loss": 0.11360197514295578,
      "eval_runtime": 60.6041,
      "eval_samples_per_second": 116.708,
      "eval_steps_per_second": 14.603,
      "step": 7000
    },
    {
      "epoch": 1.631059039742706,
      "grad_norm": 0.5837859511375427,
      "learning_rate": 0.0004584518410331309,
      "loss": 0.067,
      "step": 7100
    },
    {
      "epoch": 1.6540317022742936,
      "grad_norm": 0.5414097309112549,
      "learning_rate": 0.0004507648551003152,
      "loss": 0.0705,
      "step": 7200
    },
    {
      "epoch": 1.677004364805881,
      "grad_norm": 0.8300212025642395,
      "learning_rate": 0.0004430778691674994,
      "loss": 0.0601,
      "step": 7300
    },
    {
      "epoch": 1.6999770273374684,
      "grad_norm": 0.7662331461906433,
      "learning_rate": 0.00043539088323468365,
      "loss": 0.0613,
      "step": 7400
    },
    {
      "epoch": 1.722949689869056,
      "grad_norm": 0.9201924204826355,
      "learning_rate": 0.00042770389730186793,
      "loss": 0.0649,
      "step": 7500
    },
    {
      "epoch": 1.745922352400643,
      "grad_norm": 0.197792187333107,
      "learning_rate": 0.00042001691136905216,
      "loss": 0.0601,
      "step": 7600
    },
    {
      "epoch": 1.7688950149322307,
      "grad_norm": 0.7463710308074951,
      "learning_rate": 0.0004123299254362365,
      "loss": 0.0563,
      "step": 7700
    },
    {
      "epoch": 1.791867677463818,
      "grad_norm": 0.743771493434906,
      "learning_rate": 0.00040464293950342073,
      "loss": 0.0592,
      "step": 7800
    },
    {
      "epoch": 1.8148403399954054,
      "grad_norm": 1.6979279518127441,
      "learning_rate": 0.00039695595357060496,
      "loss": 0.0624,
      "step": 7900
    },
    {
      "epoch": 1.837813002526993,
      "grad_norm": 1.383826732635498,
      "learning_rate": 0.00038926896763778925,
      "loss": 0.0578,
      "step": 8000
    },
    {
      "epoch": 1.837813002526993,
      "eval_loss": 0.11247429251670837,
      "eval_runtime": 61.3109,
      "eval_samples_per_second": 115.363,
      "eval_steps_per_second": 14.435,
      "step": 8000
    },
    {
      "epoch": 1.8607856650585803,
      "grad_norm": 0.18213355541229248,
      "learning_rate": 0.0003815819817049735,
      "loss": 0.0595,
      "step": 8100
    },
    {
      "epoch": 1.8837583275901677,
      "grad_norm": 0.4890602231025696,
      "learning_rate": 0.00037389499577215776,
      "loss": 0.0586,
      "step": 8200
    },
    {
      "epoch": 1.906730990121755,
      "grad_norm": 0.2965359389781952,
      "learning_rate": 0.000366208009839342,
      "loss": 0.0494,
      "step": 8300
    },
    {
      "epoch": 1.9297036526533424,
      "grad_norm": 0.3813123404979706,
      "learning_rate": 0.0003585210239065262,
      "loss": 0.0549,
      "step": 8400
    },
    {
      "epoch": 1.95267631518493,
      "grad_norm": 0.08090025186538696,
      "learning_rate": 0.0003508340379737105,
      "loss": 0.0505,
      "step": 8500
    },
    {
      "epoch": 1.9756489777165174,
      "grad_norm": 0.9823183417320251,
      "learning_rate": 0.00034314705204089473,
      "loss": 0.0576,
      "step": 8600
    },
    {
      "epoch": 1.9986216402481047,
      "grad_norm": 0.07828344404697418,
      "learning_rate": 0.00033546006610807907,
      "loss": 0.0513,
      "step": 8700
    },
    {
      "epoch": 2.0215943027796923,
      "grad_norm": 0.5994260907173157,
      "learning_rate": 0.0003277730801752633,
      "loss": 0.0299,
      "step": 8800
    },
    {
      "epoch": 2.0445669653112795,
      "grad_norm": 1.1318439245224,
      "learning_rate": 0.0003201629641017757,
      "loss": 0.0337,
      "step": 8900
    },
    {
      "epoch": 2.067539627842867,
      "grad_norm": 0.18401454389095306,
      "learning_rate": 0.00031247597816895994,
      "loss": 0.0403,
      "step": 9000
    },
    {
      "epoch": 2.067539627842867,
      "eval_loss": 0.11242201924324036,
      "eval_runtime": 60.7592,
      "eval_samples_per_second": 116.41,
      "eval_steps_per_second": 14.566,
      "step": 9000
    },
    {
      "epoch": 2.090512290374454,
      "grad_norm": 0.4762534201145172,
      "learning_rate": 0.0003047889922361442,
      "loss": 0.0368,
      "step": 9100
    },
    {
      "epoch": 2.1134849529060418,
      "grad_norm": 0.3502764105796814,
      "learning_rate": 0.00029710200630332845,
      "loss": 0.0304,
      "step": 9200
    },
    {
      "epoch": 2.1364576154376294,
      "grad_norm": 1.029252290725708,
      "learning_rate": 0.0002894150203705127,
      "loss": 0.0294,
      "step": 9300
    },
    {
      "epoch": 2.1594302779692165,
      "grad_norm": 0.5969846844673157,
      "learning_rate": 0.000281728034437697,
      "loss": 0.0304,
      "step": 9400
    },
    {
      "epoch": 2.182402940500804,
      "grad_norm": 0.5620768070220947,
      "learning_rate": 0.00027404104850488125,
      "loss": 0.0329,
      "step": 9500
    },
    {
      "epoch": 2.205375603032391,
      "grad_norm": 0.7392939329147339,
      "learning_rate": 0.00026635406257206554,
      "loss": 0.0298,
      "step": 9600
    },
    {
      "epoch": 2.228348265563979,
      "grad_norm": 0.061615582555532455,
      "learning_rate": 0.00025866707663924976,
      "loss": 0.0324,
      "step": 9700
    },
    {
      "epoch": 2.2513209280955664,
      "grad_norm": 0.32832100987434387,
      "learning_rate": 0.000250980090706434,
      "loss": 0.0328,
      "step": 9800
    },
    {
      "epoch": 2.2742935906271535,
      "grad_norm": 0.08107805997133255,
      "learning_rate": 0.00024329310477361828,
      "loss": 0.0336,
      "step": 9900
    },
    {
      "epoch": 2.297266253158741,
      "grad_norm": 0.010492934845387936,
      "learning_rate": 0.0002356061188408025,
      "loss": 0.0364,
      "step": 10000
    },
    {
      "epoch": 2.297266253158741,
      "eval_loss": 0.11410824954509735,
      "eval_runtime": 61.1765,
      "eval_samples_per_second": 115.616,
      "eval_steps_per_second": 14.466,
      "step": 10000
    },
    {
      "epoch": 2.3202389156903287,
      "grad_norm": 0.6767736673355103,
      "learning_rate": 0.00022791913290798676,
      "loss": 0.029,
      "step": 10100
    },
    {
      "epoch": 2.343211578221916,
      "grad_norm": 0.07797864824533463,
      "learning_rate": 0.00022023214697517105,
      "loss": 0.035,
      "step": 10200
    },
    {
      "epoch": 2.3661842407535034,
      "grad_norm": 0.9809576272964478,
      "learning_rate": 0.0002125451610423553,
      "loss": 0.0354,
      "step": 10300
    },
    {
      "epoch": 2.3891569032850906,
      "grad_norm": 0.6058509349822998,
      "learning_rate": 0.00020485817510953956,
      "loss": 0.0291,
      "step": 10400
    },
    {
      "epoch": 2.412129565816678,
      "grad_norm": 0.5786707997322083,
      "learning_rate": 0.0001971711891767238,
      "loss": 0.0318,
      "step": 10500
    },
    {
      "epoch": 2.4351022283482657,
      "grad_norm": 0.37135666608810425,
      "learning_rate": 0.00018948420324390805,
      "loss": 0.0324,
      "step": 10600
    },
    {
      "epoch": 2.458074890879853,
      "grad_norm": 0.11202364414930344,
      "learning_rate": 0.00018179721731109233,
      "loss": 0.0254,
      "step": 10700
    },
    {
      "epoch": 2.4810475534114405,
      "grad_norm": 0.5210891962051392,
      "learning_rate": 0.0001741102313782766,
      "loss": 0.0295,
      "step": 10800
    },
    {
      "epoch": 2.5040202159430276,
      "grad_norm": 0.525005578994751,
      "learning_rate": 0.00016642324544546085,
      "loss": 0.0275,
      "step": 10900
    },
    {
      "epoch": 2.526992878474615,
      "grad_norm": 0.648139476776123,
      "learning_rate": 0.00015873625951264508,
      "loss": 0.0317,
      "step": 11000
    },
    {
      "epoch": 2.526992878474615,
      "eval_loss": 0.11083441227674484,
      "eval_runtime": 60.8296,
      "eval_samples_per_second": 116.276,
      "eval_steps_per_second": 14.549,
      "step": 11000
    },
    {
      "epoch": 2.5499655410062028,
      "grad_norm": 0.27072402834892273,
      "learning_rate": 0.00015104927357982933,
      "loss": 0.0315,
      "step": 11100
    },
    {
      "epoch": 2.57293820353779,
      "grad_norm": 0.06663301587104797,
      "learning_rate": 0.00014336228764701362,
      "loss": 0.0251,
      "step": 11200
    },
    {
      "epoch": 2.5959108660693775,
      "grad_norm": 0.7893011569976807,
      "learning_rate": 0.00013567530171419787,
      "loss": 0.0238,
      "step": 11300
    },
    {
      "epoch": 2.618883528600965,
      "grad_norm": 1.218183159828186,
      "learning_rate": 0.00012798831578138213,
      "loss": 0.0279,
      "step": 11400
    },
    {
      "epoch": 2.641856191132552,
      "grad_norm": 0.5302152037620544,
      "learning_rate": 0.00012030132984856639,
      "loss": 0.0357,
      "step": 11500
    },
    {
      "epoch": 2.66482885366414,
      "grad_norm": 0.01859872043132782,
      "learning_rate": 0.00011261434391575063,
      "loss": 0.0312,
      "step": 11600
    },
    {
      "epoch": 2.687801516195727,
      "grad_norm": 0.14803747832775116,
      "learning_rate": 0.00010492735798293489,
      "loss": 0.0325,
      "step": 11700
    },
    {
      "epoch": 2.7107741787273145,
      "grad_norm": 0.03076833114027977,
      "learning_rate": 9.724037205011916e-05,
      "loss": 0.0235,
      "step": 11800
    },
    {
      "epoch": 2.7337468412589017,
      "grad_norm": 0.40361905097961426,
      "learning_rate": 8.95533861173034e-05,
      "loss": 0.0307,
      "step": 11900
    },
    {
      "epoch": 2.7567195037904892,
      "grad_norm": 0.5924794673919678,
      "learning_rate": 8.186640018448767e-05,
      "loss": 0.0337,
      "step": 12000
    },
    {
      "epoch": 2.7567195037904892,
      "eval_loss": 0.11109727621078491,
      "eval_runtime": 64.8079,
      "eval_samples_per_second": 109.138,
      "eval_steps_per_second": 13.656,
      "step": 12000
    },
    {
      "epoch": 2.779692166322077,
      "grad_norm": 0.1457086056470871,
      "learning_rate": 7.417941425167191e-05,
      "loss": 0.0334,
      "step": 12100
    },
    {
      "epoch": 2.802664828853664,
      "grad_norm": 0.009360912255942822,
      "learning_rate": 6.649242831885617e-05,
      "loss": 0.031,
      "step": 12200
    },
    {
      "epoch": 2.8256374913852516,
      "grad_norm": 0.04216626286506653,
      "learning_rate": 5.8805442386040435e-05,
      "loss": 0.0289,
      "step": 12300
    },
    {
      "epoch": 2.848610153916839,
      "grad_norm": 0.22135251760482788,
      "learning_rate": 5.111845645322469e-05,
      "loss": 0.0278,
      "step": 12400
    },
    {
      "epoch": 2.8715828164484263,
      "grad_norm": 0.020462218672037125,
      "learning_rate": 4.343147052040895e-05,
      "loss": 0.0294,
      "step": 12500
    },
    {
      "epoch": 2.894555478980014,
      "grad_norm": 0.03331420570611954,
      "learning_rate": 3.5744484587593206e-05,
      "loss": 0.0235,
      "step": 12600
    },
    {
      "epoch": 2.9175281415116014,
      "grad_norm": 0.45881134271621704,
      "learning_rate": 2.8057498654777463e-05,
      "loss": 0.0262,
      "step": 12700
    },
    {
      "epoch": 2.9405008040431886,
      "grad_norm": 0.36246973276138306,
      "learning_rate": 2.037051272196172e-05,
      "loss": 0.034,
      "step": 12800
    },
    {
      "epoch": 2.963473466574776,
      "grad_norm": 0.04182026535272598,
      "learning_rate": 1.2683526789145976e-05,
      "loss": 0.0224,
      "step": 12900
    },
    {
      "epoch": 2.9864461291063633,
      "grad_norm": 1.4013545513153076,
      "learning_rate": 4.996540856330233e-06,
      "loss": 0.028,
      "step": 13000
    },
    {
      "epoch": 2.9864461291063633,
      "eval_loss": 0.10991289466619492,
      "eval_runtime": 60.7267,
      "eval_samples_per_second": 116.473,
      "eval_steps_per_second": 14.573,
      "step": 13000
    }
  ],
  "logging_steps": 100,
  "max_steps": 13059,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.98827082729472e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

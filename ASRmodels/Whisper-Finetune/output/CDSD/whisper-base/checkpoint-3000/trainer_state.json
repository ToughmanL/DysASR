{
  "best_metric": 0.749730110168457,
  "best_model_checkpoint": "output/CDSD/whisper-base/checkpoint-3000",
  "epoch": 1.0940919037199124,
  "eval_steps": 1000,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03646973012399708,
      "grad_norm": 1.3284339904785156,
      "learning_rate": 0.000994251467710372,
      "loss": 2.41,
      "step": 100
    },
    {
      "epoch": 0.07293946024799416,
      "grad_norm": 1.091966152191162,
      "learning_rate": 0.0009820205479452054,
      "loss": 1.0762,
      "step": 200
    },
    {
      "epoch": 0.10940919037199125,
      "grad_norm": 0.9834250807762146,
      "learning_rate": 0.0009697896281800391,
      "loss": 1.1292,
      "step": 300
    },
    {
      "epoch": 0.14587892049598833,
      "grad_norm": 1.0483314990997314,
      "learning_rate": 0.0009575587084148728,
      "loss": 1.0784,
      "step": 400
    },
    {
      "epoch": 0.18234865061998543,
      "grad_norm": 1.2900577783584595,
      "learning_rate": 0.0009453277886497065,
      "loss": 1.0435,
      "step": 500
    },
    {
      "epoch": 0.2188183807439825,
      "grad_norm": 1.2504547834396362,
      "learning_rate": 0.0009330968688845402,
      "loss": 0.9639,
      "step": 600
    },
    {
      "epoch": 0.2552881108679796,
      "grad_norm": 0.8600080609321594,
      "learning_rate": 0.0009208659491193738,
      "loss": 0.9536,
      "step": 700
    },
    {
      "epoch": 0.29175784099197666,
      "grad_norm": 1.1308350563049316,
      "learning_rate": 0.0009086350293542075,
      "loss": 0.8998,
      "step": 800
    },
    {
      "epoch": 0.3282275711159737,
      "grad_norm": 1.0418139696121216,
      "learning_rate": 0.000896404109589041,
      "loss": 0.8663,
      "step": 900
    },
    {
      "epoch": 0.36469730123997085,
      "grad_norm": 1.2335165739059448,
      "learning_rate": 0.0008841731898238748,
      "loss": 0.8657,
      "step": 1000
    },
    {
      "epoch": 0.36469730123997085,
      "eval_loss": 0.904305100440979,
      "eval_runtime": 30.2589,
      "eval_samples_per_second": 106.845,
      "eval_steps_per_second": 13.385,
      "step": 1000
    },
    {
      "epoch": 0.4011670313639679,
      "grad_norm": 1.1014580726623535,
      "learning_rate": 0.0008719422700587084,
      "loss": 0.8382,
      "step": 1100
    },
    {
      "epoch": 0.437636761487965,
      "grad_norm": 1.0823224782943726,
      "learning_rate": 0.0008597113502935421,
      "loss": 0.7966,
      "step": 1200
    },
    {
      "epoch": 0.47410649161196206,
      "grad_norm": 1.014958381652832,
      "learning_rate": 0.0008474804305283757,
      "loss": 0.7857,
      "step": 1300
    },
    {
      "epoch": 0.5105762217359592,
      "grad_norm": 1.332889199256897,
      "learning_rate": 0.0008352495107632094,
      "loss": 0.8078,
      "step": 1400
    },
    {
      "epoch": 0.5470459518599562,
      "grad_norm": 1.2486121654510498,
      "learning_rate": 0.000823018590998043,
      "loss": 0.7858,
      "step": 1500
    },
    {
      "epoch": 0.5835156819839533,
      "grad_norm": 1.489970088005066,
      "learning_rate": 0.0008107876712328768,
      "loss": 0.8001,
      "step": 1600
    },
    {
      "epoch": 0.6199854121079504,
      "grad_norm": 1.3485236167907715,
      "learning_rate": 0.0007985567514677104,
      "loss": 0.7186,
      "step": 1700
    },
    {
      "epoch": 0.6564551422319475,
      "grad_norm": 1.185165524482727,
      "learning_rate": 0.000786325831702544,
      "loss": 0.7405,
      "step": 1800
    },
    {
      "epoch": 0.6929248723559446,
      "grad_norm": 1.0713276863098145,
      "learning_rate": 0.0007740949119373777,
      "loss": 0.7408,
      "step": 1900
    },
    {
      "epoch": 0.7293946024799417,
      "grad_norm": 1.0823699235916138,
      "learning_rate": 0.0007618639921722114,
      "loss": 0.765,
      "step": 2000
    },
    {
      "epoch": 0.7293946024799417,
      "eval_loss": 0.7879160642623901,
      "eval_runtime": 32.3744,
      "eval_samples_per_second": 99.863,
      "eval_steps_per_second": 12.51,
      "step": 2000
    },
    {
      "epoch": 0.7658643326039387,
      "grad_norm": 1.224672794342041,
      "learning_rate": 0.0007496330724070451,
      "loss": 0.711,
      "step": 2100
    },
    {
      "epoch": 0.8023340627279358,
      "grad_norm": 1.1216018199920654,
      "learning_rate": 0.0007374021526418787,
      "loss": 0.6925,
      "step": 2200
    },
    {
      "epoch": 0.8388037928519329,
      "grad_norm": 1.7129127979278564,
      "learning_rate": 0.0007251712328767124,
      "loss": 0.7111,
      "step": 2300
    },
    {
      "epoch": 0.87527352297593,
      "grad_norm": 1.4816694259643555,
      "learning_rate": 0.0007130626223091978,
      "loss": 0.7333,
      "step": 2400
    },
    {
      "epoch": 0.9117432530999271,
      "grad_norm": 0.99419105052948,
      "learning_rate": 0.000700954011741683,
      "loss": 0.6848,
      "step": 2500
    },
    {
      "epoch": 0.9482129832239241,
      "grad_norm": 0.9530049562454224,
      "learning_rate": 0.0006887230919765166,
      "loss": 0.6827,
      "step": 2600
    },
    {
      "epoch": 0.9846827133479212,
      "grad_norm": 1.1339198350906372,
      "learning_rate": 0.0006764921722113503,
      "loss": 0.6525,
      "step": 2700
    },
    {
      "epoch": 1.0211524434719184,
      "grad_norm": 1.05463445186615,
      "learning_rate": 0.0006642612524461839,
      "loss": 0.615,
      "step": 2800
    },
    {
      "epoch": 1.0576221735959155,
      "grad_norm": 1.0687284469604492,
      "learning_rate": 0.0006520303326810177,
      "loss": 0.5781,
      "step": 2900
    },
    {
      "epoch": 1.0940919037199124,
      "grad_norm": 1.0254031419754028,
      "learning_rate": 0.0006397994129158513,
      "loss": 0.5512,
      "step": 3000
    },
    {
      "epoch": 1.0940919037199124,
      "eval_loss": 0.749730110168457,
      "eval_runtime": 31.0318,
      "eval_samples_per_second": 104.183,
      "eval_steps_per_second": 13.051,
      "step": 3000
    }
  ],
  "logging_steps": 100,
  "max_steps": 8226,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.61260551668736e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
